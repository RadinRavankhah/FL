{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vqqCuN2WbEn",
        "outputId": "c84376ff-3323-4857-fd8d-0374f7305ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymoo\n",
            "  Downloading pymoo-0.6.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.7.0)\n",
            "Collecting cma==3.2.2 (from pymoo)\n",
            "  Downloading cma-3.2.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting alive-progress (from pymoo)\n",
            "  Downloading alive_progress-3.2.0-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from pymoo)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.2.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (2.8.2)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo)\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting grapheme==0.6.0 (from alive-progress->pymoo)\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->pymoo) (1.17.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Downloading pymoo-0.6.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cma-3.2.2-py2.py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alive_progress-3.2.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: grapheme\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=5a025567f23414c76a9b631c354f4a191e3b140ab74524c05cde443684808fee\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/3b/0b/1b865800e916d671a24028d884698674138632a83fdfad4926\n",
            "Successfully built grapheme\n",
            "Installing collected packages: grapheme, dill, cma, about-time, alive-progress, pymoo\n",
            "Successfully installed about-time-4.2.1 alive-progress-3.2.0 cma-3.2.2 dill-0.3.9 grapheme-0.6.0 pymoo-0.6.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoFvgN4CWAKh",
        "outputId": "22bf18c9-1d09-4bd6-9275-33c77d3ddd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1639 - loss: 2.2862\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2942 - loss: 2.2338\n",
            "1\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2134 - loss: 2.2830\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3481 - loss: 2.2305\n",
            "2\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2046 - loss: 2.2438\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3706 - loss: 2.1190\n",
            "3\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1423 - loss: 2.2742\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3518 - loss: 2.2042\n",
            "4\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1070 - loss: 2.2884\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3372 - loss: 2.2249\n",
            "5\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1958 - loss: 2.2887\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3522 - loss: 2.2373\n",
            "6\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1394 - loss: 2.3018\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2333 - loss: 2.2327\n",
            "7\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0870 - loss: 2.3040\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2583 - loss: 2.2063\n",
            "8\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1477 - loss: 2.2659\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2395 - loss: 2.2094\n",
            "9\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1329 - loss: 2.2860\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2406 - loss: 2.2294\n",
            "10\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1971 - loss: 2.2909\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2655 - loss: 2.2607\n",
            "11\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1243 - loss: 2.2896\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3075 - loss: 2.2289\n",
            "12\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1566 - loss: 2.2906\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2270 - loss: 2.2522\n",
            "13\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1335 - loss: 2.2779\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3682 - loss: 2.1888\n",
            "14\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1448 - loss: 2.3007\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3599 - loss: 2.2484\n",
            "15\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1782 - loss: 2.2644\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2258 - loss: 2.2038\n",
            "16\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1360 - loss: 2.2903\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2135 - loss: 2.2467\n",
            "17\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1322 - loss: 2.3088\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2559 - loss: 2.2421\n",
            "18\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1357 - loss: 2.2967\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3371 - loss: 2.2230\n",
            "19\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1422 - loss: 2.3034\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2310 - loss: 2.2020\n",
            "20\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1374 - loss: 2.2813\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2677 - loss: 2.2162\n",
            "21\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1491 - loss: 2.2866\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3096 - loss: 2.2576\n",
            "22\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1197 - loss: 2.2953\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2650 - loss: 2.2346\n",
            "23\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1208 - loss: 2.2947\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4020 - loss: 2.2262\n",
            "24\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1034 - loss: 2.2831\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3338 - loss: 2.2066\n",
            "25\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1243 - loss: 2.2973\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2391 - loss: 2.2557\n",
            "26\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1508 - loss: 2.2754\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3361 - loss: 2.2154\n",
            "27\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1407 - loss: 2.2890\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4152 - loss: 2.2194\n",
            "28\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1427 - loss: 2.2767\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2849 - loss: 2.1965\n",
            "29\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1545 - loss: 2.2826\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3706 - loss: 2.2229\n",
            "30\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0646 - loss: 2.3041\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2649 - loss: 2.2320\n",
            "31\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1360 - loss: 2.2946\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4163 - loss: 2.2075\n",
            "32\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1236 - loss: 2.2998\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3098 - loss: 2.2115\n",
            "33\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1554 - loss: 2.2858\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2834 - loss: 2.2137\n",
            "34\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1431 - loss: 2.2743\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2721 - loss: 2.2137\n",
            "35\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1263 - loss: 2.3017\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3737 - loss: 2.2201\n",
            "36\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1043 - loss: 2.3134\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2906 - loss: 2.2495\n",
            "37\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.2659 - loss: 2.2372\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5127 - loss: 2.1147\n",
            "38\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.2411 - loss: 2.2914\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3756 - loss: 2.2280\n",
            "39\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1414 - loss: 2.2805\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3503 - loss: 2.2200\n",
            "40\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1304 - loss: 2.2741\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1712 - loss: 2.1998\n",
            "41\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1104 - loss: 2.3038\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2888 - loss: 2.2198\n",
            "42\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1245 - loss: 2.2969\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3033 - loss: 2.2425\n",
            "43\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1070 - loss: 2.2952\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2374 - loss: 2.2536\n",
            "44\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1131 - loss: 2.2993\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2337 - loss: 2.2514\n",
            "45\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1285 - loss: 2.2881\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3601 - loss: 2.1946\n",
            "46\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1605 - loss: 2.2823\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3046 - loss: 2.2335\n",
            "47\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1058 - loss: 2.2907\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3819 - loss: 2.2418\n",
            "48\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1067 - loss: 2.2893\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2585 - loss: 2.2106\n",
            "49\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1426 - loss: 2.2974\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3994 - loss: 2.2254\n",
            "50\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0896 - loss: 2.3012\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1167 - loss: 2.2287\n",
            "51\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1004 - loss: 2.2996\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1047 - loss: 2.2786\n",
            "52\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1096 - loss: 2.2989\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3099 - loss: 2.2354\n",
            "53\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1308 - loss: 2.3011\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2984 - loss: 2.2119\n",
            "54\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1914 - loss: 2.2711\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5038 - loss: 2.1793\n",
            "55\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1010 - loss: 2.3003\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3606 - loss: 2.2389\n",
            "56\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1247 - loss: 2.2904\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3775 - loss: 2.1657\n",
            "57\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1216 - loss: 2.2878\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3515 - loss: 2.1999\n",
            "58\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0909 - loss: 2.2970\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2132 - loss: 2.2234\n",
            "59\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1038 - loss: 2.3089\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1372 - loss: 2.2340\n",
            "60\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1553 - loss: 2.2803\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2791 - loss: 2.1883\n",
            "61\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1304 - loss: 2.2899\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2269 - loss: 2.2389\n",
            "62\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1472 - loss: 2.2959\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4110 - loss: 2.2096\n",
            "63\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0740 - loss: 2.3048\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2048 - loss: 2.2492\n",
            "64\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1184 - loss: 2.3111\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3410 - loss: 2.2324\n",
            "65\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1117 - loss: 2.2987\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2632 - loss: 2.2391\n",
            "66\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1095 - loss: 2.2777\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2686 - loss: 2.2300\n",
            "67\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1526 - loss: 2.2944\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1950 - loss: 2.2671\n",
            "68\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1051 - loss: 2.3030\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1892 - loss: 2.2523\n",
            "69\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0929 - loss: 2.2966\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2618 - loss: 2.2159\n",
            "70\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1898 - loss: 2.2911\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3631 - loss: 2.1992\n",
            "71\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1095 - loss: 2.2948\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4092 - loss: 2.2129\n",
            "72\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1444 - loss: 2.2599\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3902 - loss: 2.1407\n",
            "73\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1294 - loss: 2.2911\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3872 - loss: 2.2020\n",
            "74\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0958 - loss: 2.3029\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3189 - loss: 2.2412\n",
            "75\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1271 - loss: 2.3020\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.2963 - loss: 2.2296\n",
            "76\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1071 - loss: 2.3059\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2308 - loss: 2.2250\n",
            "77\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1366 - loss: 2.2936\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3436 - loss: 2.1675\n",
            "78\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1186 - loss: 2.2959\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2244 - loss: 2.2686\n",
            "79\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1785 - loss: 2.2807\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2426 - loss: 2.2240\n",
            "80\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1437 - loss: 2.2780\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2896 - loss: 2.2229\n",
            "81\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2056 - loss: 2.2816\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2915 - loss: 2.2102\n",
            "82\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1434 - loss: 2.2912\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3141 - loss: 2.2467\n",
            "83\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1131 - loss: 2.3078\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2842 - loss: 2.2564\n",
            "84\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1235 - loss: 2.2785\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2529 - loss: 2.2087\n",
            "85\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1240 - loss: 2.2598\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2230 - loss: 2.1795\n",
            "86\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1036 - loss: 2.3034\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2595 - loss: 2.2201\n",
            "87\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1030 - loss: 2.2992\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2899 - loss: 2.2209\n",
            "88\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1424 - loss: 2.2857\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2707 - loss: 2.2351\n",
            "89\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1134 - loss: 2.2900\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2452 - loss: 2.2135\n",
            "90\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1442 - loss: 2.2882\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2704 - loss: 2.2423\n",
            "91\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1059 - loss: 2.2972\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1738 - loss: 2.2305\n",
            "92\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1412 - loss: 2.2916\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3068 - loss: 2.2438\n",
            "93\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1161 - loss: 2.2933\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3309 - loss: 2.2202\n",
            "94\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1510 - loss: 2.2845\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2625 - loss: 2.2059\n",
            "95\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1289 - loss: 2.2996\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3218 - loss: 2.2162\n",
            "96\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1031 - loss: 2.2944\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3017 - loss: 2.2328\n",
            "97\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1339 - loss: 2.2888\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3962 - loss: 2.1709\n",
            "98\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1588 - loss: 2.2869\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.1993 - loss: 2.2099\n",
            "99\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1525 - loss: 2.2893\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2974 - loss: 2.2171\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1116 - loss: 2.3025\n",
            "Global Model Accuracy: 0.1116\n",
            "==========================================================\n",
            "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
            "==========================================================\n",
            "     1 |       10 |      2 |             - |             -\n",
            "     2 |       20 |      2 |  0.000000E+00 |             f\n",
            "     3 |       30 |      5 |  1.2405499359 |         ideal\n",
            "     4 |       40 |     10 |  0.8370204550 |         ideal\n",
            "     5 |       50 |     10 |  0.1370227284 |         ideal\n",
            "     6 |       60 |     10 |  0.3055882323 |         ideal\n",
            "     7 |       70 |     10 |  0.2330758907 |         ideal\n",
            "     8 |       80 |     10 |  0.0812345118 |         ideal\n",
            "     9 |       90 |     10 |  0.0415910999 |         ideal\n",
            "    10 |      100 |     10 |  0.0217295008 |         ideal\n",
            "Best Pareto Front (Bitstrings):\n",
            "TrueTrueFalseFalseTrueFalseTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseFalseFalseFalseTrueTrueTrueFalseTrueTrueTrueTrueFalseFalseTrueFalseTrueFalseTrueFalseTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseTrueFalseTrueFalseTrueTrueFalseFalseFalseTrueTrueFalseFalseFalseFalseTrueFalseTrueTrueTrueFalseTrueTrueTrueFalseTrueFalseTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueTrueFalseFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueFalseTrueTrueTrueTrueTrueFalseFalseTrueTrueTrueFalseTrueTrueFalseFalseFalseTrueFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseTrueFalseFalseFalseFalseTrueTrueTrueFalseTrueTrueTrueFalseFalseTrueTrueFalseTrueTrueFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseTrueTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueTrueFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueFalseTrueFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueTrueFalseFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueFalseFalseFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueTrueTrueFalseTrueTrueTrueTrueFalseFalseTrueFalseTrueFalseTrueFalseTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseTrueFalseTrueTrueFalseFalseFalseTrueTrueFalseFalseFalseFalseTrueFalseTrueTrueTrueFalseTrueTrueTrueFalseTrueFalseTrue\n",
            "TrueFalseTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueTrueFalseFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseTrueFalseTrueFalseTrueTrueFalseFalseFalseTrueTrueFalseFalseFalseFalseTrueFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueTrueFalseFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueFalseFalseTrueTrueFalseFalseTrueTrueFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueFalseTrueFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueTrueFalseFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseFalseTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueTrueTrueFalseTrueTrueTrueTrueTrueFalseFalseTrueTrueTrueFalseTrueTrueFalseTrueTrueTrueTrueTrueFalseFalseFalseTrueFalseTrueTrueFalseTrueTrue\n",
            "TrueTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseTrueFalseFalseFalseFalseTrueTrueTrueFalseTrueTrueTrueFalseFalseTrueTrueFalseTrueTrueFalseFalseFalseTrueTrueFalseTrueTrueTrueTrueTrueTrueTrueTrueFalseFalseFalseTrueTrueTrueFalseFalseFalseTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueTrueTrueTrueTrueFalseFalseTrueTrueFalseFalseTrueTrueFalseTrueTrueTrueTrueFalseTrueFalseFalseTrueFalseTrueFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrue\n",
            "FalseTrueTrueTrueTrueTrueTrueTrueFalseFalseTrueFalseFalseTrueFalseFalseTrueTrueFalseFalseTrueTrueTrueTrueFalseTrueTrueFalseTrueTrueTrueFalseTrueTrueTrueTrueFalseFalseTrueFalseTrueFalseTrueFalseFalseTrueTrueFalseFalseFalseTrueFalseTrueFalseTrueTrueTrueTrueFalseTrueFalseTrueFalseTrueTrueFalseTrueTrueFalseFalseTrueTrueFalseTrueTrueTrueFalseFalseTrueTrueTrueFalseTrueTrueFalseTrueFalseTrueTrueTrueFalseFalseFalseTrueFalseTrueTrueFalseTrueFalse\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "current_learning_iteration = 0\n",
        "\n",
        "# Device Class\n",
        "class Device:\n",
        "    def __init__(self, device_id, ram, storage, cpu, bandwidth, battery, charging):\n",
        "        self.device_id = device_id\n",
        "        self.ram = ram\n",
        "        self.storage = storage\n",
        "        self.cpu = cpu\n",
        "        self.bandwidth = bandwidth\n",
        "        self.battery = battery\n",
        "        self.charging = charging\n",
        "        self.energy_consumption = ram + storage + cpu + bandwidth\n",
        "        self.model = self.create_model()\n",
        "        self.data = None  # Placeholder for dataset partition\n",
        "\n",
        "        self.number_of_times_fitted = 0\n",
        "\n",
        "    def create_model(self):\n",
        "        model = keras.Sequential([\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                      loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "\n",
        "# Load dataset from CSV\n",
        "csv_file = 'data/devices.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "\n",
        "# Convert CSV rows into device objects\n",
        "devices = []\n",
        "for _, row in df.iterrows():\n",
        "    device = Device(\n",
        "        row['id'], row['ram'], row['storage'], row['cpu'], row['bandwidth'], row['battery'],\n",
        "        row.get('charging', 0)\n",
        "    )\n",
        "    devices.append(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (_, _) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize data and reshape for CNN\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)  # Add channel dimension\n",
        "\n",
        "# Shuffle data\n",
        "indices = np.arange(len(x_train))\n",
        "np.random.shuffle(indices)\n",
        "x_train, y_train = x_train[indices], y_train[indices]\n",
        "\n",
        "# Split into global test set (20%) and training set (80%)\n",
        "split_index = int(0.8 * len(x_train))\n",
        "x_train_devices, y_train_devices = x_train[:split_index], y_train[:split_index]\n",
        "x_test_global, y_test_global = x_train[split_index:], y_train[split_index:]\n",
        "\n",
        "\n",
        "# Split dataset among devices\n",
        "num_devices = len(devices)\n",
        "split_size = len(x_train_devices) // num_devices\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    start = i * split_size\n",
        "    end = (i + 1) * split_size if i < num_devices - 1 else len(x_train_devices)\n",
        "    device.data = (x_train_devices[start:end], y_train_devices[start:end])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open('data/bitstring.txt', 'r') as f:\n",
        "    bitstring = f.read()\n",
        "\n",
        "bitstring = [int(bit) for bit in bitstring.split(',')]\n",
        "\n",
        "current_learning_iteration += 1\n",
        "for device in devices:\n",
        "    print(int(device.device_id))\n",
        "    if bitstring[int(device.device_id)] == 1:\n",
        "        device.model.fit(device.data[0], device.data[1], epochs=2, verbose=1)\n",
        "        device.number_of_times_fitted += 1\n",
        "\n",
        "\n",
        "# Global Model\n",
        "# Define the global model with the same architecture\n",
        "def create_global_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "global_model = create_global_model()\n",
        "\n",
        "\n",
        "def aggregate_weights(global_model, devices):\n",
        "    \"\"\"Averages model weights from all devices and updates the global model.\"\"\"\n",
        "\n",
        "    num_devices = len(devices)\n",
        "    if num_devices == 0:\n",
        "        print(\"No devices available for aggregation.\")\n",
        "        return\n",
        "\n",
        "    # Get the weights of all devices\n",
        "    device_weights = [device.model.get_weights() for device in devices]\n",
        "\n",
        "    # Compute the average of the weights across all devices\n",
        "    avg_weights = [np.mean(np.array(layer_weights), axis=0) for layer_weights in zip(*device_weights)]\n",
        "\n",
        "    # Set the global model's weights to the averaged weights\n",
        "    global_model.set_weights(avg_weights)\n",
        "\n",
        "# Call this function after training the local models:\n",
        "aggregate_weights(global_model, devices)\n",
        "\n",
        "\n",
        "test_loss, test_acc = global_model.evaluate(x_test_global, y_test_global)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
        "from pymoo.operators.crossover.pntx import TwoPointCrossover\n",
        "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
        "from pymoo.operators.selection.tournament import TournamentSelection\n",
        "# from pymoo.util.termination.f_tol import MultiObjectiveSpaceToleranceTermination\n",
        "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
        "\n",
        "# Parameters\n",
        "NUM_DEVICES = num_devices   # Number of devices (length of bitstring)\n",
        "POPULATION_SIZE = 10\n",
        "NUM_GENERATIONS = 10\n",
        "\n",
        "# Step 1: Define the Problem\n",
        "import numpy as np\n",
        "from pymoo.core.problem import Problem\n",
        "\n",
        "class FederatedLearningProblem(Problem):\n",
        "    def __init__(self, num_devices, devices, global_model, x_test_global, y_test_global):\n",
        "        super().__init__(\n",
        "            n_var=num_devices,         # Number of variables (bitstring length)\n",
        "            n_obj=3,                   # Number of objectives\n",
        "            n_constr=0,                # No constraints\n",
        "            xl=np.zeros(num_devices),  # Lower bound (0)\n",
        "            xu=np.ones(num_devices),   # Upper bound (1)\n",
        "            type_var=np.bool_          # Binary variables (bitstrings)\n",
        "        )\n",
        "        self.devices = devices\n",
        "        self.global_model = global_model\n",
        "        self.x_test_global = x_test_global\n",
        "        self.y_test_global = y_test_global\n",
        "\n",
        "        # Save the initial global model weights\n",
        "        self.initial_global_weights = global_model.get_weights()\n",
        "\n",
        "    def _evaluate(self, X, out, *args, **kwargs):\n",
        "        \"\"\"Evaluates objective values for each solution in the population.\"\"\"\n",
        "        num_solutions = len(X)\n",
        "        F = np.zeros((num_solutions, 3))  # Initialize objective matrix\n",
        "\n",
        "        for i, bitstring in enumerate(X):\n",
        "            # Reset the global model to its initial state\n",
        "            self.global_model.set_weights(self.initial_global_weights)\n",
        "\n",
        "            # Update device participation based on the bitstring\n",
        "            selected_devices = [device for device, bit in zip(self.devices, bitstring) if bit == 1]\n",
        "\n",
        "            # Train local models for selected devices\n",
        "            for device in selected_devices:\n",
        "                device.model.fit(device.data[0], device.data[1], epochs=1, verbose=0)\n",
        "\n",
        "            # Aggregate weights to update the global model\n",
        "            aggregate_weights(self.global_model, selected_devices)\n",
        "\n",
        "            # Distribute the updated global model back to all devices\n",
        "            for device in self.devices:\n",
        "                device.model.set_weights(self.global_model.get_weights())\n",
        "\n",
        "            # Objective 1: Hardware Objectives (maximize)\n",
        "            hardware_score = sum(\n",
        "                device.ram + device.storage + device.cpu + device.bandwidth + device.battery + device.charging\n",
        "                for device in selected_devices\n",
        "            )\n",
        "            F[i, 0] = -hardware_score  # Minimize (negative of hardware score)\n",
        "\n",
        "            # Objective 2: Fairness (prioritize devices with lowest local accuracy)\n",
        "            local_accuracies = []\n",
        "            for device in self.devices:\n",
        "                _, accuracy = device.model.evaluate(device.data[0], device.data[1], verbose=0)\n",
        "                local_accuracies.append(accuracy)\n",
        "            # Fairness score: Sum of (1 - accuracy) for selected devices\n",
        "            # This prioritizes devices with lower local accuracy\n",
        "            fairness_score = sum(1 - local_accuracies[j] for j, bit in enumerate(bitstring) if bit == 1)\n",
        "            F[i, 1] = -fairness_score  # Minimize (negative of fairness score)\n",
        "\n",
        "            # Objective 3: Global Model Accuracy (maximize)\n",
        "            _, global_accuracy = self.global_model.evaluate(self.x_test_global, self.y_test_global, verbose=0)\n",
        "            F[i, 2] = 1 - global_accuracy  # Minimize (1 - accuracy)\n",
        "\n",
        "        out[\"F\"] = F  # Set the objective values\n",
        "\n",
        "\n",
        "\n",
        "problem = FederatedLearningProblem(\n",
        "    num_devices=NUM_DEVICES,\n",
        "    devices=devices,\n",
        "    global_model=global_model,\n",
        "    x_test_global=x_test_global,\n",
        "    y_test_global=y_test_global\n",
        ")\n",
        "\n",
        "\n",
        "# Step 2: Configure NSGA-II Algorithm\n",
        "algorithm = NSGA2(\n",
        "    pop_size=POPULATION_SIZE,\n",
        "    sampling=BinaryRandomSampling(),      # Random bitstrings\n",
        "    crossover=TwoPointCrossover(),        # Two-point crossover\n",
        "    mutation=BitflipMutation(),           # Bit flip mutation\n",
        "    eliminate_duplicates=True             # Avoid duplicate solutions\n",
        ")\n",
        "\n",
        "# Step 3: Run Optimization\n",
        "res = minimize(\n",
        "    problem=problem,\n",
        "    algorithm=algorithm,\n",
        "    # termination=MultiObjectiveSpaceToleranceTermination(tol=1e-6, n_last=10, nth_gen=5, n_max_gen=NUM_GENERATIONS),\n",
        "    termination=DefaultMultiObjectiveTermination(n_max_gen=NUM_GENERATIONS),\n",
        "    seed=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Step 4: Extract the Best Pareto Front\n",
        "pareto_front = res.F   # Objective values of solutions in Pareto front\n",
        "pareto_solutions = res.X  # Corresponding bitstrings\n",
        "\n",
        "# Print the Best Pareto Front Solutions\n",
        "print(\"Best Pareto Front (Bitstrings):\")\n",
        "for bitstring in pareto_solutions:\n",
        "    print(\"\".join(map(str, bitstring)))\n"
      ]
    }
  ]
}