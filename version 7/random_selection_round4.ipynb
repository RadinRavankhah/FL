{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cM8_9f7DQ0P"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cE4i_ysDeI4",
        "outputId": "206a1e08-bf7c-4146-db82-e4b11c33880a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymoo in d:\\github repos\\fl\\venv\\lib\\site-packages (0.6.1.3)\n",
            "Requirement already satisfied: numpy>=1.15 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
            "Requirement already satisfied: cma==3.2.2 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
            "Requirement already satisfied: alive-progress in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
            "Requirement already satisfied: dill in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
            "Requirement already satisfied: Deprecated in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\github repos\\fl\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Requirement already satisfied: about-time==4.2.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ZDVPjAODQ0R"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import random\n",
        "from tensorflow.keras.models import clone_model\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6jG5c5fDQ0S"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eRjGPts0DQ0T"
      },
      "outputs": [],
      "source": [
        "# CLASSES\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, devices_list):\n",
        "        self.model = Server.create_model()\n",
        "        self.current_learning_iteration = 0\n",
        "        self.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES = []\n",
        "        self.x_test_global = []\n",
        "        self.y_test_global = []\n",
        "        self.devices = devices_list\n",
        "\n",
        "    # def evaluate(self, verbose = 1):\n",
        "    #     test_loss, test_acc = self.model.evaluate(self.x_test_global, self.y_test_global, verbose)\n",
        "    #     return test_loss, test_acc\n",
        "\n",
        "    def evaluate(self, x_test=None, y_test=None, verbose = 1):\n",
        "        if x_test is None and y_test is None:\n",
        "            test_loss, test_acc = self.model.evaluate(self.x_test_global, self.y_test_global, verbose)\n",
        "            return test_loss, test_acc\n",
        "        test_loss, test_acc = self.model.evaluate(x_test, y_test, verbose=verbose)\n",
        "        return test_loss, test_acc\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def set_aggregated_weight(self):\n",
        "        self.model.set_weight(Server.aggregate_weights())\n",
        "\n",
        "    def give_global_model_weights_to_bitstring_devices(self, bitstring):\n",
        "        for device in self.devices:\n",
        "            if int(bitstring[int(device.id)]) == 1:\n",
        "                device.model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def create_model():\n",
        "        model = keras.Sequential([\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                        # new\n",
        "                        loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def aggregate_weights(self, bitstring):\n",
        "        \"\"\"Computes the weighted average of model weights from all devices and updates the global model.\"\"\"\n",
        "        def sum_all_nested_lists(list_of_lists):\n",
        "            def recursive_sum(lists):\n",
        "                if isinstance(lists[0], list):\n",
        "                    return [recursive_sum([lst[i] for lst in lists]) for i in range(len(lists[0]))]\n",
        "                else:\n",
        "                    return sum(lists)\n",
        "\n",
        "            return recursive_sum(list_of_lists)\n",
        "\n",
        "        def multiply_nested_list(lst, factor):\n",
        "            result = []\n",
        "            for item in lst:\n",
        "                if isinstance(item, list):\n",
        "                    # Recursively handle sublists\n",
        "                    result.append(multiply_nested_list(item, factor))\n",
        "                else:\n",
        "                    # Multiply number\n",
        "                    result.append(item * factor)\n",
        "            return result\n",
        "\n",
        "        selected_devices = []\n",
        "        for device in self.devices:\n",
        "            if int(bitstring[int(device.id)]) == 1:\n",
        "                selected_devices.append(device)\n",
        "\n",
        "        num_devices = len(selected_devices)\n",
        "        if num_devices == 0:\n",
        "            print(\"No devices available for aggregation.\")\n",
        "            return\n",
        "\n",
        "        device_participation_ratio = []\n",
        "        data_lengths = []\n",
        "\n",
        "        for device in selected_devices:\n",
        "            print(\"*******************\")\n",
        "            print(device.id)\n",
        "            device_participation_ratio.append(device.last_round_participated / self.current_learning_iteration)\n",
        "            # print(\"this device's participation ratio:\")\n",
        "            # print(device.last_round_participated / self.current_learning_iteration)\n",
        "            data_lengths.append(len(device.data[0]))\n",
        "            # print(\"this device's data to all ratio:\")\n",
        "            # print(len(device.data[0])/60000.0)\n",
        "\n",
        "        sum_data = 0\n",
        "        for data_len in data_lengths:\n",
        "            sum_data += data_len\n",
        "\n",
        "        data_fractions = []\n",
        "        for device in selected_devices:\n",
        "            data_fractions.append(len(device.data[0])/float(sum_data))\n",
        "\n",
        "\n",
        "\n",
        "        # new\n",
        "        combined_weights = [fraction * ratio for fraction, ratio in zip(data_fractions, device_participation_ratio)]\n",
        "        total_weight = sum(combined_weights)\n",
        "        normalized_weights = [w / total_weight for w in combined_weights]\n",
        "        print(normalized_weights)\n",
        "\n",
        "\n",
        "        aggregated_weights_devices = []\n",
        "        for d in range(len(selected_devices)):\n",
        "            # aggregated_weights_devices.append(multiply_nested_list(selected_devices[d].model.get_weights(), data_fractions[d]*device_participation_ratio[d]))\n",
        "            aggregated_weights_devices.append(multiply_nested_list(self.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES[int(selected_devices[d].id)], normalized_weights[d]))\n",
        "\n",
        "        aggregated_weights = sum_all_nested_lists(aggregated_weights_devices)\n",
        "        # TODO: Weighted multiplication for each node in each layer of the neural network of the received devices and then summing\n",
        "        #       the related parts together so that we get a full weighted average of all these devices' models\n",
        "\n",
        "        print(\"Aggregated weights:\")\n",
        "        for layer_idx, layer_weights in enumerate(aggregated_weights):\n",
        "            print(f\"Layer {layer_idx}: {layer_weights.shape}\")\n",
        "            \n",
        "        \n",
        "        return aggregated_weights\n",
        "\n",
        "\n",
        "class Device:\n",
        "    def __init__(self, id, ram, storage, cpu, bandwidth, battery, charging):\n",
        "        self.id = id\n",
        "        self.ram = ram\n",
        "        self.storage = storage\n",
        "        self.cpu = cpu\n",
        "        self.bandwidth = bandwidth\n",
        "        self.battery = battery\n",
        "        self.charging = charging\n",
        "        self.model = Server.create_model()\n",
        "        self.last_round_participated = 0\n",
        "        self.data = None  # Placeholder for dataset partition\n",
        "        self.test_data = None\n",
        "        self.number_of_times_fitted = 0\n",
        "        \n",
        "    def lose_battery(self):\n",
        "        if float(self.battery) > 0.3:\n",
        "            self.battery -= 0.3\n",
        "        else:\n",
        "            self.battery = 0\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3jpr0sQDQ0U"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YSAsTf5GDQ0V"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def fit_bitstring_devices(bitstring, server: Server, epochs=7):\n",
        "    '''\n",
        "    server: for using its \"current_learning_iteration\" variable\n",
        "    '''\n",
        "\n",
        "    server.current_learning_iteration += 1\n",
        "    for device in server.devices:\n",
        "        if bitstring[int(device.id)] == 1:\n",
        "            # TODO:\n",
        "            # makes it so that the random selection might choose a device that's been turned off\n",
        "            # if the device is off, don't fit, use old weights saved on the server.\n",
        "            # if the device is on, fit, update the weights saved on the server.\n",
        "            if device.battery == 0:\n",
        "                continue\n",
        "            \n",
        "            device.lose_battery()\n",
        "            \n",
        "            device.model.fit(device.data[0], device.data[1], epochs=epochs, verbose=1)\n",
        "            print(device.id)\n",
        "            device.last_round_participated = server.current_learning_iteration\n",
        "            server.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES[int(device.id)] = device.model.get_weights()\n",
        "            device.number_of_times_fitted += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def niid_labeldir_split(x_data, y_data, num_clients, beta, seed=None):\n",
        "    num_classes = 10\n",
        "    y_indices = np.array([np.argmax(label) for label in y_data])  # From one-hot to class index\n",
        "\n",
        "    rng = np.random.default_rng(seed)  # Local random generator\n",
        "\n",
        "    # Prepare client partitions\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for k in range(num_classes):\n",
        "        idx_k = np.where(y_indices == k)[0]\n",
        "        rng.shuffle(idx_k)\n",
        "\n",
        "        # Dirichlet distribution for class k\n",
        "        proportions = rng.dirichlet(np.repeat(beta, num_clients))\n",
        "\n",
        "        # Scale proportions to match the number of available samples\n",
        "        proportions = np.array([int(p * len(idx_k)) for p in proportions])\n",
        "        # Fix total due to rounding\n",
        "        while sum(proportions) < len(idx_k):\n",
        "            proportions[np.argmin(proportions)] += 1\n",
        "        while sum(proportions) > len(idx_k):\n",
        "            proportions[np.argmax(proportions)] -= 1\n",
        "\n",
        "        start = 0\n",
        "        for i in range(num_clients):\n",
        "            size = proportions[i]\n",
        "            client_indices[i].extend(idx_k[start:start + size])\n",
        "            start += size\n",
        "\n",
        "    return client_indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_M11zZDQ0W"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SKaZfTDQ0W"
      },
      "source": [
        "### Load Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp1Ba7wUDQ0W",
        "outputId": "5d017ddf-25eb-46b0-f6e3-5ec61e2bf722"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Github Repos\\FL\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset from CSV\n",
        "csv_file = 'devices.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Convert CSV rows into device objects\n",
        "devices = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    device = Device(\n",
        "        row['id'], row['ram'], row['storage'], row['cpu'], row['bandwidth'], row['battery'],\n",
        "        row.get('charging', 0)\n",
        "    )\n",
        "    devices.append(device)\n",
        "\n",
        "\n",
        "# LIMIT TO 30 DEVICES\n",
        "devices = devices[:30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dQSqJi6DQ0Y"
      },
      "source": [
        "### Object Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OvVt3SZzDQ0Z"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "server = Server(devices_list=devices)\n",
        "server.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES = [None for _ in range(len(devices))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hodxc61dDQ0Z"
      },
      "source": [
        "### Split Data Among Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ySmgcIuDQ0Z",
        "outputId": "5b32be3b-f118-4bda-c12d-0bfdf1e74f2c"
      },
      "outputs": [],
      "source": [
        "SEED = 1\n",
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Convert labels to categorical (one-hot encoded)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Normalize data and reshape for CNN\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)  # Add channel dimension\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1)  # Add channel dimension\n",
        "\n",
        "\n",
        "# Lower the amount of data for devices\n",
        "x_train = x_train[:int(len(x_train)/8)]\n",
        "y_train = y_train[:int(len(y_train)/8)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Correct test split\n",
        "split_index = int(0.8 * len(x_test))\n",
        "x_test_devices, y_test_devices = x_test[:split_index], y_test[:split_index]\n",
        "server.x_test_global, server.y_test_global = x_test[split_index:], y_test[split_index:]\n",
        "\n",
        "# Training data (for devices)\n",
        "x_train_devices, y_train_devices = x_train, y_train\n",
        "\n",
        "# Split training data among devices\n",
        "beta = 0.5  # lower = more skewed\n",
        "num_devices = len(devices)\n",
        "split_indices = niid_labeldir_split(x_train_devices, y_train_devices, num_devices, beta, seed=SEED)\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    idxs = split_indices[i]\n",
        "    device.data = (x_train_devices[idxs], y_train_devices[idxs])\n",
        "\n",
        "# Split test data (device-level)\n",
        "split_size = len(x_test_devices) // num_devices\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    start = i * split_size\n",
        "    end = (i + 1) * split_size if i < num_devices - 1 else len(x_test_devices)\n",
        "    device.test_data = (x_test_devices[start:end], y_test_devices[start:end])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXlJ81PvDQ0Z"
      },
      "source": [
        "### Load Other Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtD_ODCDQ0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFERpbpDQ0Z"
      },
      "source": [
        "## First Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtoM8SQmHqJs",
        "outputId": "0b9ad23e-e90e-47f5-f416-bd856dfd56a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1043 - loss: 2.3137 \n",
            "Global Model Accuracy: 0.1175\n",
            "------------------------------------------------------------\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1362 - loss: 2.2631  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3897 - loss: 2.0033 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3906 - loss: 1.7492 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4173 - loss: 1.5520 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5077 - loss: 1.3629 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5774 - loss: 1.3438 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6781 - loss: 1.0908 \n",
            "0.0\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2314 - loss: 2.2444  \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4491 - loss: 2.0044 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6445 - loss: 1.7709 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: 1.5352 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6883 - loss: 1.2411 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7446 - loss: 1.1545 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.9776 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0962 - loss: 2.3010  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1573 - loss: 2.2270 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2661 - loss: 2.1571 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2938 - loss: 2.1205 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3550 - loss: 2.0411 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4305 - loss: 1.9680 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4541 - loss: 1.8867 \n",
            "2.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1322 - loss: 2.2657  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4216 - loss: 2.0904 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4477 - loss: 1.9231 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4325 - loss: 1.7876 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4573 - loss: 1.6091 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4759 - loss: 1.4777 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4182 - loss: 1.5020 \n",
            "3.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2250 - loss: 2.2277  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4905 - loss: 1.9174 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4713 - loss: 1.7058 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4830 - loss: 1.5993 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5045 - loss: 1.4749 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5187 - loss: 1.3917 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5171 - loss: 1.3215 \n",
            "4.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2282 - loss: 2.2517  \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 1.8658 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7111 - loss: 1.4547 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7616 - loss: 1.0642 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 1.0122 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.8435 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.7990 \n",
            "5.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2497 - loss: 2.2366  \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2617 - loss: 1.9937 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3309 - loss: 1.7455 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5320 - loss: 1.4440 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7707 - loss: 1.2229 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.9853 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.9099 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1784 - loss: 2.2783  \n",
            "Epoch 2/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5112 - loss: 2.1006 \n",
            "Epoch 3/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5037 - loss: 1.9169 \n",
            "Epoch 4/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6319 - loss: 1.7014 \n",
            "Epoch 5/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6639 - loss: 1.5130 \n",
            "Epoch 6/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 1.2568 \n",
            "Epoch 7/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 1.1611 \n",
            "7.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1197 - loss: 2.2954  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1682 - loss: 2.2345 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2761 - loss: 2.1890 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3836 - loss: 2.1258 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2865 - loss: 2.0717 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2667 - loss: 2.0610 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2896 - loss: 1.9636 \n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2402 - loss: 2.2570  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4119 - loss: 2.0121 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4137 - loss: 1.7972 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3497 - loss: 1.7031 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4037 - loss: 1.5383 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5390 - loss: 1.3351 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6350 - loss: 1.2680 \n",
            "9.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: 2.1190  \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: 1.6036 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7096 - loss: 1.2164 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7061 - loss: 1.0458 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.8827 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.8229 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.7482 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3671 - loss: 2.2148  \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4032 - loss: 1.9712 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4168 - loss: 1.7570 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4355 - loss: 1.5598 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3958 - loss: 1.4727 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4316 - loss: 1.3777 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5736 - loss: 1.2280 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2355 - loss: 2.2349  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4423 - loss: 1.8460 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4618 - loss: 1.4697 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6249 - loss: 1.2414 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7565 - loss: 1.0388 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.9332 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.7513 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1467 - loss: 2.2979  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4571 - loss: 2.1871 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5589 - loss: 2.0688 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5743 - loss: 1.9640 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5921 - loss: 1.8521 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6289 - loss: 1.7026 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6994 - loss: 1.5353 \n",
            "13.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2400 - loss: 2.2403  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5343 - loss: 1.8018 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5034 - loss: 1.6046 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5352 - loss: 1.4064 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5370 - loss: 1.3318 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5132 - loss: 1.2600 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5387 - loss: 1.1981 \n",
            "14.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1337 - loss: 2.2650  \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4305 - loss: 2.0710 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3008 - loss: 1.8626 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4770 - loss: 1.6163 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5174 - loss: 1.4326 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7343 - loss: 1.3457 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7359 - loss: 1.2730 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1314 - loss: 2.2601  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4348 - loss: 2.1088 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4272 - loss: 1.9620 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4895 - loss: 1.7696 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4185 - loss: 1.6399 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4476 - loss: 1.5332 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5794 - loss: 1.5328 \n",
            "16.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1972 - loss: 2.2886  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6331 - loss: 2.0532 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5900 - loss: 1.8598 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5651 - loss: 1.6669 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5982 - loss: 1.4660 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6400 - loss: 1.3825 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6600 - loss: 1.3036 \n",
            "17.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0765 - loss: 2.3038  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2851 - loss: 2.2316 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4870 - loss: 2.1493 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4745 - loss: 2.0759 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4922 - loss: 1.9921 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 1.9130 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4755 - loss: 1.8692 \n",
            "18.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2322 - loss: 2.2592  \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4664 - loss: 2.0743 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4882 - loss: 1.8988 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4495 - loss: 1.7788 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4692 - loss: 1.5903 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5186 - loss: 1.4558 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 1.4108 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3219 - loss: 2.2517  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 1.9717 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5330 - loss: 1.7015 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6551 - loss: 1.5145 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6871 - loss: 1.3301 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6968 - loss: 1.1705 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7326 - loss: 1.1043 \n",
            "20.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1013 - loss: 2.2952  \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4662 - loss: 2.0935 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5689 - loss: 1.8463 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6034 - loss: 1.6178 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 1.4587 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5691 - loss: 1.3570 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5631 - loss: 1.3142 \n",
            "21.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4173 - loss: 2.1689  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 1.7942 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5997 - loss: 1.5036 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6863 - loss: 1.2237 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7583 - loss: 1.1829 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7712 - loss: 1.1034 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 1.0245 \n",
            "22.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3404 - loss: 2.2506  \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3564 - loss: 2.1537 \n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3703 - loss: 2.0489 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4193 - loss: 1.9191 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4195 - loss: 1.8428 \n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4390 - loss: 1.7368 \n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4885 - loss: 1.6378 \n",
            "23.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1365 - loss: 2.2947  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2072 - loss: 2.2497 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3272 - loss: 2.1959 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3671 - loss: 2.1591 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4458 - loss: 2.1229 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4852 - loss: 2.0868 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5305 - loss: 2.0419 \n",
            "24.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1232 - loss: 2.2979  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4872 - loss: 2.1766 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 2.0713 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5884 - loss: 1.9630 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5806 - loss: 1.8639 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5480 - loss: 1.7712 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5328 - loss: 1.7080 \n",
            "25.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4713 - loss: 2.1104  \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4715 - loss: 1.6602 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4504 - loss: 1.4296 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4963 - loss: 1.2368 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6702 - loss: 1.0411 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.8662 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.7471 \n",
            "26.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2236 - loss: 2.2356  \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5152 - loss: 1.7780 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5654 - loss: 1.4526 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 1.1858 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 1.0153 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.9055 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.7663 \n",
            "27.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1716 - loss: 2.2561      \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6311 - loss: 1.9416 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 1.5609 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 1.2190 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 1.0422 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.9152 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.9093 \n",
            "28.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0568 - loss: 2.2943  \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2505 - loss: 2.2320 \n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3413 - loss: 2.1766 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3296 - loss: 2.1251 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3022 - loss: 2.0769 \n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3162 - loss: 2.0046 \n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3335 - loss: 1.9509 \n",
            "29.0\n",
            "*******************\n",
            "0.0\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "2.0\n",
            "*******************\n",
            "3.0\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "14.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "18.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "20.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "26.0\n",
            "*******************\n",
            "27.0\n",
            "*******************\n",
            "28.0\n",
            "*******************\n",
            "29.0\n",
            "[0.0408, 0.06426666666666667, 0.0252, 0.020266666666666665, 0.03493333333333333, 0.045066666666666665, 0.0476, 0.0572, 0.014, 0.0424, 0.04346666666666667, 0.028266666666666666, 0.04253333333333333, 0.019333333333333334, 0.03626666666666667, 0.03, 0.021466666666666665, 0.0164, 0.014666666666666666, 0.032933333333333335, 0.0364, 0.027466666666666667, 0.042133333333333335, 0.0112, 0.015733333333333332, 0.019466666666666667, 0.05466666666666667, 0.064, 0.04186666666666667, 0.01]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "------------------------------------------------------------\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6094 - loss: 1.8465\n",
            "Global Model Accuracy: 0.6090\n"
          ]
        }
      ],
      "source": [
        "# First Iteration\n",
        "bitstring = [1 for _ in range(len(devices))]\n",
        "print(bitstring)\n",
        "\n",
        "# Load global model weights\n",
        "server.model.load_weights(\"my_model.weights.h5\")\n",
        "\n",
        "# global model sends its weights to all devices\n",
        "server.give_global_model_weights_to_bitstring_devices(bitstring)\n",
        "\n",
        "test_loss, test_acc = server.evaluate(verbose=0)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "print(\"------------------------------------------------------------\")\n",
        "fit_bitstring_devices(bitstring, server)\n",
        "server.model.set_weights(server.aggregate_weights(bitstring))\n",
        "print(\"------------------------------------------------------------\")\n",
        "test_loss, test_acc = server.evaluate(verbose=0)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XliqF4L-Sd",
        "outputId": "613396eb-907f-4edd-8fc4-1446524053b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymoo in d:\\github repos\\fl\\venv\\lib\\site-packages (0.6.1.3)\n",
            "Requirement already satisfied: numpy>=1.15 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
            "Requirement already satisfied: cma==3.2.2 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
            "Requirement already satisfied: alive-progress in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
            "Requirement already satisfied: dill in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
            "Requirement already satisfied: Deprecated in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\github repos\\fl\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Requirement already satisfied: about-time==4.2.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWyAIYBDQ0a"
      },
      "source": [
        "## NSGA2 Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hiEDWLPjHqJt"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "NUM_ROUNDS = 3 # was 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_random_binary_list(size):\n",
        "    return [random.randint(0, 1) for _ in range(size)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM0EBc17HqJu",
        "outputId": "2f73767f-beaf-451d-eef0-46457ebd604e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 797us/step - accuracy: 0.6088 - loss: 1.8464\n",
            "(1.8566051721572876, 0.609000027179718)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 801us/step - accuracy: 0.6088 - loss: 1.8464\n",
            "(1.8566051721572876, 0.609000027179718)\n",
            "Bitstring:  [0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0]\n",
            "16 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803us/step - accuracy: 0.6088 - loss: 1.8464\n",
            "Global Model Accuracy: 0.6090\n",
            "------------------------------------------------------------\n",
            "1  1\n",
            "1  2\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4683 - loss: 1.7189 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5208 - loss: 1.3121 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5569 - loss: 1.1702 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 1.0633 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.9311 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.9312 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.7963 \n",
            "4.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 1.5831 \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 1.0104 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.8294 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.6569 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.6431 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.5033 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.5093 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6840 - loss: 1.7833 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6989 - loss: 1.5986 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6729 - loss: 1.4880 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5792 - loss: 1.3788 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6937 - loss: 1.2938 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7405 - loss: 1.2278 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7603 - loss: 1.1502 \n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6900 - loss: 1.4695 \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6920 - loss: 0.8821 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8194 - loss: 0.7286 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7939 - loss: 0.6429 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.5217 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: 0.4448 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9003 - loss: 0.4207 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 1.5671 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5912 - loss: 1.1754 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.9415 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.8622 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.7477 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.6157 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.6009 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6589 - loss: 1.5813 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.9378 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.7441 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.5845 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8592 - loss: 0.5519 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.4858 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8935 - loss: 0.4695 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6555 - loss: 1.7531 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6871 - loss: 1.4016 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7451 - loss: 1.1805 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 1.0113 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7069 - loss: 1.0356 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7555 - loss: 0.9129 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 0.8860 \n",
            "13.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 1.7512 \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6239 - loss: 1.3840 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 1.2473 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6431 - loss: 1.1499 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 1.0962 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.8777 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6423 - loss: 0.9693 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7349 - loss: 1.6036 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 1.1905 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7069 - loss: 1.0503 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7278 - loss: 0.9677 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7604 - loss: 0.8811 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.8736 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7527 - loss: 0.8259 \n",
            "17.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7793 - loss: 1.5642 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 1.0880 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.8760 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7929 - loss: 0.8397 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 0.7566 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.7002 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.6008 \n",
            "20.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 1.6447 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6604 - loss: 1.1867 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.9326 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8204 - loss: 0.8974 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.7803 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.7515 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.6315 \n",
            "21.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6461 - loss: 1.8150 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6678 - loss: 1.4187 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6682 - loss: 1.2481 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6810 - loss: 1.1588 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6456 - loss: 1.1274 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.9887 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7682 - loss: 0.8914 \n",
            "25.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 1.4342 \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7567 - loss: 0.9541 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.7197 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.6216 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.5509 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.4483 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.4313 \n",
            "26.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6852 - loss: 1.6334 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 1.0533 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.7438 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.6907 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.6644 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.6116 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9028 - loss: 0.4880 \n",
            "28.0\n",
            "2  3\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "20.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "26.0\n",
            "*******************\n",
            "28.0\n",
            "[0.07087785743270661, 0.09657784390639794, 0.05802786419586095, 0.0284052482077641, 0.08819153253077235, 0.057351548762342754, 0.0862978493169214, 0.039226295144055186, 0.06086838901663735, 0.03327471932909509, 0.07385364534018667, 0.05572839172189909, 0.015961044231029353, 0.03949682131746246, 0.11091573109698363, 0.08494521844988502]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "2  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811us/step - accuracy: 0.6319 - loss: 1.2848\n",
            "Global Model Accuracy: 0.6300\n",
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782us/step - accuracy: 0.6319 - loss: 1.2848\n",
            "(1.2980598211288452, 0.6299999952316284)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 783us/step - accuracy: 0.6319 - loss: 1.2848\n",
            "(1.2980598211288452, 0.6299999952316284)\n",
            "Bitstring:  [0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n",
            "13 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 800us/step - accuracy: 0.6319 - loss: 1.2848\n",
            "Global Model Accuracy: 0.6300\n",
            "------------------------------------------------------------\n",
            "2  1\n",
            "2  2\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 1.0744 \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.8584 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.7175 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.6262 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.5280 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.4681 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.4371 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5726 - loss: 1.3315 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.9245 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.7432 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 0.7420 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8214 - loss: 0.6880 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.6166 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.6184 \n",
            "3.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7683 - loss: 1.1740 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7821 - loss: 1.0175 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8078 - loss: 0.8967 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8269 - loss: 0.8880 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9036 - loss: 0.7440 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.7438 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8876 - loss: 0.6841 \n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 1.0952 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.7479 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.6037 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.5677 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 0.5225 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.4419 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.3922 \n",
            "14.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 0.9227 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.6522 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.6264 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.5911 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.5280 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.4538 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.4232 \n",
            "20.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 1.0194 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.7047 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 0.6455 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.5832 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.4772 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.4518 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.4361 \n",
            "21.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 1.0581 \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8186 - loss: 0.6673 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.5645 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.4858 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.4771 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.4380 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3888 \n",
            "27.0\n",
            "3  3\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "3.0\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "14.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "20.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "27.0\n",
            "[0.18188679245283018, 0.05735849056603773, 0.06591194968553458, 0.05396226415094339, 0.03962264150943396, 0.04, 0.10264150943396226, 0.020251572327044026, 0.1030188679245283, 0.07773584905660377, 0.03974842767295598, 0.03672955974842767, 0.1811320754716981]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "3  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 806us/step - accuracy: 0.8468 - loss: 0.8633\n",
            "Global Model Accuracy: 0.8295\n",
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 883us/step - accuracy: 0.8468 - loss: 0.8633\n",
            "(0.9086422324180603, 0.8295000195503235)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 919us/step - accuracy: 0.8468 - loss: 0.8633\n",
            "(0.9086422324180603, 0.8295000195503235)\n",
            "Bitstring:  [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
            "18 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 867us/step - accuracy: 0.8468 - loss: 0.8633\n",
            "Global Model Accuracy: 0.8295\n",
            "------------------------------------------------------------\n",
            "3  1\n",
            "3  2\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.8069 \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.6187 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.9291 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.4725 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.4013 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.7131 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.3994 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8210 - loss: 0.8871 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 0.7763 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8786 - loss: 0.6690 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9067 - loss: 0.6268 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8630 - loss: 0.6108 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9230 - loss: 0.5329 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9119 - loss: 0.5348 \n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.8113 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9373 - loss: 0.4638 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.4527 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9077 - loss: 0.4222 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.3997 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.3383 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.2990 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.6959 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.5742 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.4931 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.4565 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.3695 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9237 - loss: 0.3375 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.3041 \n",
            "14.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.7723 \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9286 - loss: 0.5032 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 0.4687 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9098 - loss: 0.4221 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.3619 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.3314 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9426 - loss: 0.3144 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7913 - loss: 0.9787 \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8564 - loss: 0.6421 \n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8603 - loss: 0.5529 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8385 - loss: 0.5282 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8895 - loss: 0.4588 \n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9092 - loss: 0.4546 \n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8780 - loss: 0.4805 \n",
            "23.0\n",
            "4  3\n",
            "*******************\n",
            "0.0\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "14.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "28.0\n",
            "[0.029804227135482617, 0.18778611084055713, 0.06954319664945943, 0.040907762734976136, 0.03097302035648193, 0.0635044316742963, 0.08259472095061848, 0.02824583617415019, 0.10597058537060486, 0.015681309048407522, 0.023960261030486023, 0.0962306418622772, 0.0601928508814649, 0.030778221486315382, 0.032726210187980914, 0.01149313333982663, 0.028440635044316744, 0.06116684523229765]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "4  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 846us/step - accuracy: 0.7995 - loss: 0.8601\n",
            "Global Model Accuracy: 0.7980\n"
          ]
        }
      ],
      "source": [
        "\n",
        "all_runs_fronts = []  # Stores results across runs\n",
        "all_runs_solutions = []\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "    # Step 3: Run Optimization\n",
        "    print(\"GLOBAL MODEL BEFORE OPTIMIZATION\")\n",
        "    print(server.evaluate())\n",
        "\n",
        "    print(\"GLOBAL MODEL AFTER OPTIMIZATION\")\n",
        "    print(server.evaluate())\n",
        "\n",
        "    bitstring = generate_random_binary_list(len(devices))\n",
        "    print(\"Bitstring: \", bitstring)\n",
        "    print(bitstring.count(1), \"devices selected randomly\")\n",
        "\n",
        "    a = server.model.get_weights()\n",
        "    test_loss, test_acc = server.evaluate()\n",
        "    print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    print(server.current_learning_iteration, \" 1\")\n",
        "    server.give_global_model_weights_to_bitstring_devices(bitstring)\n",
        "    print(server.current_learning_iteration, \" 2\")\n",
        "    fit_bitstring_devices(bitstring, server=server, epochs=7)\n",
        "    print(server.current_learning_iteration, \" 3\")\n",
        "    server.model.set_weights(server.aggregate_weights(bitstring))\n",
        "    print(server.current_learning_iteration, \" 4\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    test_loss, test_acc = server.evaluate()\n",
        "    print(f\"Global Model Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Choose a generation and run\n",
        "gen_idx = 0\n",
        "run_idx = 0\n",
        "\n",
        "for run_idx in range(len(all_runs_fronts)):\n",
        "    for gen_idx in range(len(all_runs_fronts[run_idx])):\n",
        "        \n",
        "        front = all_runs_fronts[run_idx][gen_idx]\n",
        "\n",
        "        fig = go.Figure(data=[go.Scatter3d(\n",
        "            x=front[:, 0],\n",
        "            y=front[:, 1],\n",
        "            z=front[:, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=5,\n",
        "                color=front[:, 2],  # Color by third objective\n",
        "                colorscale='Viridis',\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Pareto Front - Run {run_idx}, Gen {gen_idx}\",\n",
        "            scene=dict(\n",
        "                xaxis=dict(title=\"Objective 1\", range=[0, 1]),\n",
        "                yaxis=dict(title=\"Objective 2\", range=[0, 1]),\n",
        "                zaxis=dict(title=\"Objective 3\", range=[0, 1])\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 816us/step - accuracy: 0.7995 - loss: 0.8601\n",
            "(0.8898978233337402, 0.7979999780654907)\n"
          ]
        }
      ],
      "source": [
        "print(server.evaluate())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
