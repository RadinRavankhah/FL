{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cM8_9f7DQ0P"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cE4i_ysDeI4",
        "outputId": "206a1e08-bf7c-4146-db82-e4b11c33880a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymoo in d:\\github repos\\fl\\venv\\lib\\site-packages (0.6.1.3)\n",
            "Requirement already satisfied: numpy>=1.15 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
            "Requirement already satisfied: cma==3.2.2 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
            "Requirement already satisfied: alive-progress in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
            "Requirement already satisfied: dill in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
            "Requirement already satisfied: Deprecated in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\github repos\\fl\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Requirement already satisfied: about-time==4.2.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ZDVPjAODQ0R"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import random\n",
        "from tensorflow.keras.models import clone_model\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6jG5c5fDQ0S"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eRjGPts0DQ0T"
      },
      "outputs": [],
      "source": [
        "# CLASSES\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, devices_list):\n",
        "        self.model = Server.create_model()\n",
        "        self.current_learning_iteration = 0\n",
        "        self.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES = []\n",
        "        self.x_test_global = []\n",
        "        self.y_test_global = []\n",
        "        self.devices = devices_list\n",
        "\n",
        "    # def evaluate(self, verbose = 1):\n",
        "    #     test_loss, test_acc = self.model.evaluate(self.x_test_global, self.y_test_global, verbose)\n",
        "    #     return test_loss, test_acc\n",
        "\n",
        "    def evaluate(self, x_test=None, y_test=None, verbose = 1):\n",
        "        if x_test is None and y_test is None:\n",
        "            test_loss, test_acc = self.model.evaluate(self.x_test_global, self.y_test_global, verbose)\n",
        "            return test_loss, test_acc\n",
        "        test_loss, test_acc = self.model.evaluate(x_test, y_test, verbose=verbose)\n",
        "        return test_loss, test_acc\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def set_aggregated_weight(self):\n",
        "        self.model.set_weight(Server.aggregate_weights())\n",
        "\n",
        "    def give_global_model_weights_to_bitstring_devices(self, bitstring):\n",
        "        for device in self.devices:\n",
        "            if int(bitstring[int(device.id)]) == 1:\n",
        "                device.model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def create_model():\n",
        "        model = keras.Sequential([\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                        # new\n",
        "                        loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def aggregate_weights(self, bitstring):\n",
        "        \"\"\"Computes the weighted average of model weights from all devices and updates the global model.\"\"\"\n",
        "        def sum_all_nested_lists(list_of_lists):\n",
        "            def recursive_sum(lists):\n",
        "                if isinstance(lists[0], list):\n",
        "                    return [recursive_sum([lst[i] for lst in lists]) for i in range(len(lists[0]))]\n",
        "                else:\n",
        "                    return sum(lists)\n",
        "\n",
        "            return recursive_sum(list_of_lists)\n",
        "\n",
        "        def multiply_nested_list(lst, factor):\n",
        "            result = []\n",
        "            for item in lst:\n",
        "                if isinstance(item, list):\n",
        "                    # Recursively handle sublists\n",
        "                    result.append(multiply_nested_list(item, factor))\n",
        "                else:\n",
        "                    # Multiply number\n",
        "                    result.append(item * factor)\n",
        "            return result\n",
        "\n",
        "        selected_devices = []\n",
        "        for device in self.devices:\n",
        "            if int(bitstring[int(device.id)]) == 1:\n",
        "                selected_devices.append(device)\n",
        "\n",
        "        num_devices = len(selected_devices)\n",
        "        if num_devices == 0:\n",
        "            print(\"No devices available for aggregation.\")\n",
        "            return\n",
        "\n",
        "        device_participation_ratio = []\n",
        "        data_lengths = []\n",
        "\n",
        "        for device in selected_devices:\n",
        "            print(\"*******************\")\n",
        "            print(device.id)\n",
        "            device_participation_ratio.append(device.last_round_participated / self.current_learning_iteration)\n",
        "            # print(\"this device's participation ratio:\")\n",
        "            # print(device.last_round_participated / self.current_learning_iteration)\n",
        "            data_lengths.append(len(device.data[0]))\n",
        "            # print(\"this device's data to all ratio:\")\n",
        "            # print(len(device.data[0])/60000.0)\n",
        "\n",
        "        sum_data = 0\n",
        "        for data_len in data_lengths:\n",
        "            sum_data += data_len\n",
        "\n",
        "        data_fractions = []\n",
        "        for device in selected_devices:\n",
        "            data_fractions.append(len(device.data[0])/float(sum_data))\n",
        "\n",
        "\n",
        "\n",
        "        # new\n",
        "        combined_weights = [fraction * ratio for fraction, ratio in zip(data_fractions, device_participation_ratio)]\n",
        "        total_weight = sum(combined_weights)\n",
        "        normalized_weights = [w / total_weight for w in combined_weights]\n",
        "        print(normalized_weights)\n",
        "\n",
        "\n",
        "        aggregated_weights_devices = []\n",
        "        for d in range(len(selected_devices)):\n",
        "            # aggregated_weights_devices.append(multiply_nested_list(selected_devices[d].model.get_weights(), data_fractions[d]*device_participation_ratio[d]))\n",
        "            aggregated_weights_devices.append(multiply_nested_list(self.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES[int(selected_devices[d].id)], normalized_weights[d]))\n",
        "\n",
        "        aggregated_weights = sum_all_nested_lists(aggregated_weights_devices)\n",
        "        # TODO: Weighted multiplication for each node in each layer of the neural network of the received devices and then summing\n",
        "        #       the related parts together so that we get a full weighted average of all these devices' models\n",
        "\n",
        "        print(\"Aggregated weights:\")\n",
        "        for layer_idx, layer_weights in enumerate(aggregated_weights):\n",
        "            print(f\"Layer {layer_idx}: {layer_weights.shape}\")\n",
        "            \n",
        "        \n",
        "        return aggregated_weights\n",
        "\n",
        "\n",
        "class Device:\n",
        "    def __init__(self, id, ram, storage, cpu, bandwidth, battery, charging):\n",
        "        self.id = id\n",
        "        self.ram = ram\n",
        "        self.storage = storage\n",
        "        self.cpu = cpu\n",
        "        self.bandwidth = bandwidth\n",
        "        self.battery = battery\n",
        "        self.charging = charging\n",
        "        self.model = Server.create_model()\n",
        "        self.last_round_participated = 0\n",
        "        self.data = None  # Placeholder for dataset partition\n",
        "        self.test_data = None\n",
        "        self.number_of_times_fitted = 0\n",
        "        \n",
        "    def lose_battery(self):\n",
        "        if float(self.battery) > 0.3:\n",
        "            self.battery -= 0.3\n",
        "        else:\n",
        "            self.battery = 0\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3jpr0sQDQ0U"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YSAsTf5GDQ0V"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def fit_bitstring_devices(bitstring, server: Server, epochs=7):\n",
        "    '''\n",
        "    server: for using its \"current_learning_iteration\" variable\n",
        "    '''\n",
        "\n",
        "    server.current_learning_iteration += 1\n",
        "    for device in server.devices:\n",
        "        if bitstring[int(device.id)] == 1:\n",
        "            # TODO:\n",
        "            # makes it so that the random selection might choose a device that's been turned off\n",
        "            # if the device is off, don't fit, use old weights saved on the server.\n",
        "            # if the device is on, fit, update the weights saved on the server.\n",
        "            if device.battery == 0:\n",
        "                continue\n",
        "            \n",
        "            device.lose_battery()\n",
        "            \n",
        "            device.model.fit(device.data[0], device.data[1], epochs=epochs, verbose=1)\n",
        "            print(device.id)\n",
        "            device.last_round_participated = server.current_learning_iteration\n",
        "            server.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES[int(device.id)] = device.model.get_weights()\n",
        "            device.number_of_times_fitted += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def niid_labeldir_split(x_data, y_data, num_clients, beta, seed=None):\n",
        "    num_classes = 10\n",
        "    y_indices = np.array([np.argmax(label) for label in y_data])  # From one-hot to class index\n",
        "\n",
        "    rng = np.random.default_rng(seed)  # Local random generator\n",
        "\n",
        "    # Prepare client partitions\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for k in range(num_classes):\n",
        "        idx_k = np.where(y_indices == k)[0]\n",
        "        rng.shuffle(idx_k)\n",
        "\n",
        "        # Dirichlet distribution for class k\n",
        "        proportions = rng.dirichlet(np.repeat(beta, num_clients))\n",
        "\n",
        "        # Scale proportions to match the number of available samples\n",
        "        proportions = np.array([int(p * len(idx_k)) for p in proportions])\n",
        "        # Fix total due to rounding\n",
        "        while sum(proportions) < len(idx_k):\n",
        "            proportions[np.argmin(proportions)] += 1\n",
        "        while sum(proportions) > len(idx_k):\n",
        "            proportions[np.argmax(proportions)] -= 1\n",
        "\n",
        "        start = 0\n",
        "        for i in range(num_clients):\n",
        "            size = proportions[i]\n",
        "            client_indices[i].extend(idx_k[start:start + size])\n",
        "            start += size\n",
        "\n",
        "    return client_indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_M11zZDQ0W"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SKaZfTDQ0W"
      },
      "source": [
        "### Load Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp1Ba7wUDQ0W",
        "outputId": "5d017ddf-25eb-46b0-f6e3-5ec61e2bf722"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Github Repos\\FL\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset from CSV\n",
        "csv_file = 'devices.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Convert CSV rows into device objects\n",
        "devices = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    device = Device(\n",
        "        row['id'], row['ram'], row['storage'], row['cpu'], row['bandwidth'], row['battery'],\n",
        "        row.get('charging', 0)\n",
        "    )\n",
        "    devices.append(device)\n",
        "\n",
        "\n",
        "# LIMIT TO 30 DEVICES\n",
        "devices = devices[:30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dQSqJi6DQ0Y"
      },
      "source": [
        "### Object Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OvVt3SZzDQ0Z"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "server = Server(devices_list=devices)\n",
        "server.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES = [None for _ in range(len(devices))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hodxc61dDQ0Z"
      },
      "source": [
        "### Split Data Among Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ySmgcIuDQ0Z",
        "outputId": "5b32be3b-f118-4bda-c12d-0bfdf1e74f2c"
      },
      "outputs": [],
      "source": [
        "SEED = 1\n",
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Convert labels to categorical (one-hot encoded)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Normalize data and reshape for CNN\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)  # Add channel dimension\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1)  # Add channel dimension\n",
        "\n",
        "\n",
        "# Lower the amount of data for devices\n",
        "x_train = x_train[:int(len(x_train)/8)]\n",
        "y_train = y_train[:int(len(y_train)/8)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Correct test split\n",
        "split_index = int(0.8 * len(x_test))\n",
        "x_test_devices, y_test_devices = x_test[:split_index], y_test[:split_index]\n",
        "server.x_test_global, server.y_test_global = x_test[split_index:], y_test[split_index:]\n",
        "\n",
        "# Training data (for devices)\n",
        "x_train_devices, y_train_devices = x_train, y_train\n",
        "\n",
        "# Split training data among devices\n",
        "beta = 0.5  # lower = more skewed\n",
        "num_devices = len(devices)\n",
        "split_indices = niid_labeldir_split(x_train_devices, y_train_devices, num_devices, beta, seed=SEED)\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    idxs = split_indices[i]\n",
        "    device.data = (x_train_devices[idxs], y_train_devices[idxs])\n",
        "\n",
        "# Split test data (device-level)\n",
        "split_size = len(x_test_devices) // num_devices\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    start = i * split_size\n",
        "    end = (i + 1) * split_size if i < num_devices - 1 else len(x_test_devices)\n",
        "    device.test_data = (x_test_devices[start:end], y_test_devices[start:end])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXlJ81PvDQ0Z"
      },
      "source": [
        "### Load Other Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtD_ODCDQ0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFERpbpDQ0Z"
      },
      "source": [
        "## First Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtoM8SQmHqJs",
        "outputId": "0b9ad23e-e90e-47f5-f416-bd856dfd56a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1043 - loss: 2.3137 \n",
            "Global Model Accuracy: 0.1175\n",
            "------------------------------------------------------------\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1198 - loss: 2.2651      \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4437 - loss: 1.9767 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4281 - loss: 1.7341 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3880 - loss: 1.5983 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4849 - loss: 1.4255 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5931 - loss: 1.2802 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6706 - loss: 1.1988 \n",
            "0.0\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2187 - loss: 2.2480  \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5289 - loss: 2.0107 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 1.7804 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 1.5039 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6663 - loss: 1.3338 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7350 - loss: 1.0671 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 1.0258 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0725 - loss: 2.3109  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1488 - loss: 2.2246 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3044 - loss: 2.1536 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3002 - loss: 2.0955 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3471 - loss: 2.0383 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4320 - loss: 1.9613\n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4421 - loss: 1.9105 \n",
            "2.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1435 - loss: 2.2670  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3991 - loss: 2.1195 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4820 - loss: 1.8997 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4364 - loss: 1.7791 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3956 - loss: 1.6898 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4286 - loss: 1.5511 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4686 - loss: 1.3984 \n",
            "3.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2329 - loss: 2.2277  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4982 - loss: 1.9116 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4765 - loss: 1.6958 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4954 - loss: 1.5611 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4984 - loss: 1.4918 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4959 - loss: 1.4513 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5012 - loss: 1.3680 \n",
            "4.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2505 - loss: 2.2474  \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7446 - loss: 1.8478 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7540 - loss: 1.4132 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7168 - loss: 1.1326 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7215 - loss: 0.9967 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.8883 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7266 - loss: 0.8649 \n",
            "5.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2581 - loss: 2.2352  \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2732 - loss: 1.9868 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3266 - loss: 1.7389 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6475 - loss: 1.4356 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 1.1844 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.9684 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.8041 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1849 - loss: 2.2782  \n",
            "Epoch 2/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4858 - loss: 2.0985 \n",
            "Epoch 3/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5242 - loss: 1.9094 \n",
            "Epoch 4/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6411 - loss: 1.7165 \n",
            "Epoch 5/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6997 - loss: 1.4311 \n",
            "Epoch 6/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 1.2807 \n",
            "Epoch 7/7\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7126 - loss: 1.1973 \n",
            "7.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0971 - loss: 2.2947  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1634 - loss: 2.2283 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3329 - loss: 2.1777 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3767 - loss: 2.1229 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3587 - loss: 2.0541 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3333 - loss: 2.0160 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3028 - loss: 1.9564 \n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2076 - loss: 2.2554  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4310 - loss: 2.0061 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4208 - loss: 1.7682 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3698 - loss: 1.6669 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4209 - loss: 1.4931 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4764 - loss: 1.3906 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5901 - loss: 1.2814 \n",
            "9.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5458 - loss: 2.1138  \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5976 - loss: 1.6063 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6741 - loss: 1.2440 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.9967 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7284 - loss: 0.9055 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.8064 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.7319 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4192 - loss: 2.2073  \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4192 - loss: 1.9776 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4249 - loss: 1.7488 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4078 - loss: 1.6256 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3834 - loss: 1.4685 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4433 - loss: 1.3305 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5752 - loss: 1.2247 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2087 - loss: 2.2378  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4589 - loss: 1.8390 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4599 - loss: 1.4711 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6676 - loss: 1.2420 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 1.0195 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.8289 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8617 - loss: 0.7571 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1409 - loss: 2.2914  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4646 - loss: 2.1873 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6325 - loss: 2.0539 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6249 - loss: 1.9460 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6132 - loss: 1.8195 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6007 - loss: 1.7119 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6617 - loss: 1.5918 \n",
            "13.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2594 - loss: 2.2396  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5101 - loss: 1.8540 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5309 - loss: 1.5600 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4984 - loss: 1.5041 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5131 - loss: 1.3539 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5039 - loss: 1.2992 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5462 - loss: 1.2044 \n",
            "14.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1141 - loss: 2.2682  \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4987 - loss: 2.0677 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4037 - loss: 1.7804 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5409 - loss: 1.5950 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4803 - loss: 1.4367 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5193 - loss: 1.3816 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 1.3424 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1394 - loss: 2.2629  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5220 - loss: 2.0992 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4088 - loss: 1.8868 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4107 - loss: 1.7227 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4759 - loss: 1.5598 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 1.5178 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4999 - loss: 1.5591 \n",
            "16.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1991 - loss: 2.2866  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5512 - loss: 2.0791 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6068 - loss: 1.8619 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6344 - loss: 1.5992 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5787 - loss: 1.4725 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5979 - loss: 1.3442 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6400 - loss: 1.2825 \n",
            "17.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0421 - loss: 2.3127      \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2804 - loss: 2.2307 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3891 - loss: 2.1733 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4709 - loss: 2.0989 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4953 - loss: 2.0203 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5068 - loss: 1.9321 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5104 - loss: 1.8355 \n",
            "18.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2409 - loss: 2.2604  \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4992 - loss: 2.0800 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4732 - loss: 1.9329 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4482 - loss: 1.7314 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4745 - loss: 1.6351 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5216 - loss: 1.4925 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 1.3175 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2952 - loss: 2.2543  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6057 - loss: 1.9922 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5225 - loss: 1.6709 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6990 - loss: 1.4128 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6709 - loss: 1.3523 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7388 - loss: 1.1385 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7444 - loss: 1.0661 \n",
            "20.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0564 - loss: 2.2940      \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5159 - loss: 2.0947 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5049 - loss: 1.8906 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5390 - loss: 1.6753 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5637 - loss: 1.5347 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5769 - loss: 1.3494 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5946 - loss: 1.2657 \n",
            "21.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4502 - loss: 2.1646  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5062 - loss: 1.8209 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5610 - loss: 1.4928 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6513 - loss: 1.3376 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7469 - loss: 1.1824 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 1.0575 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 1.0326 \n",
            "22.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3406 - loss: 2.2522 \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4111 - loss: 2.1340\n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4211 - loss: 2.0269 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4390 - loss: 1.9327\n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5019 - loss: 1.8335\n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5138 - loss: 1.7420\n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5158 - loss: 1.6538\n",
            "23.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1154 - loss: 2.2973  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1923 - loss: 2.2503 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2882 - loss: 2.2123 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3893 - loss: 2.1655 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3888 - loss: 2.1290 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4258 - loss: 2.0992 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5156 - loss: 2.0500 \n",
            "24.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0922 - loss: 2.3007  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4378 - loss: 2.1778 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5382 - loss: 2.0955 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5718 - loss: 1.9660 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5615 - loss: 1.8755 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 1.8026 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5492 - loss: 1.6860 \n",
            "25.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4400 - loss: 2.1271  \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4686 - loss: 1.6634 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4956 - loss: 1.3771 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5305 - loss: 1.1882 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6405 - loss: 1.0718 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - loss: 0.8794\n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.7423 \n",
            "26.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2413 - loss: 2.2343  \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5131 - loss: 1.7736 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5755 - loss: 1.4776 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: 1.1550 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7097 - loss: 1.0716 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.9076 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.7917 \n",
            "27.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1632 - loss: 2.2544      \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6356 - loss: 1.9286 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6737 - loss: 1.5742 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6946 - loss: 1.2705 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 1.0521 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.8773 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8466 - loss: 0.7829 \n",
            "28.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0712 - loss: 2.2897 \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3029 - loss: 2.2235\n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3647 - loss: 2.1678\n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4027 - loss: 2.1129\n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3988 - loss: 2.0623\n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4282 - loss: 2.0148\n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4187 - loss: 1.9627\n",
            "29.0\n",
            "*******************\n",
            "0.0\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "2.0\n",
            "*******************\n",
            "3.0\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "14.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "18.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "20.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "26.0\n",
            "*******************\n",
            "27.0\n",
            "*******************\n",
            "28.0\n",
            "*******************\n",
            "29.0\n",
            "[0.0408, 0.06426666666666667, 0.0252, 0.020266666666666665, 0.03493333333333333, 0.045066666666666665, 0.0476, 0.0572, 0.014, 0.0424, 0.04346666666666667, 0.028266666666666666, 0.04253333333333333, 0.019333333333333334, 0.03626666666666667, 0.03, 0.021466666666666665, 0.0164, 0.014666666666666666, 0.032933333333333335, 0.0364, 0.027466666666666667, 0.042133333333333335, 0.0112, 0.015733333333333332, 0.019466666666666667, 0.05466666666666667, 0.064, 0.04186666666666667, 0.01]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "------------------------------------------------------------\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6176 - loss: 1.8464\n",
            "Global Model Accuracy: 0.6135\n"
          ]
        }
      ],
      "source": [
        "# First Iteration\n",
        "bitstring = [1 for _ in range(len(devices))]\n",
        "print(bitstring)\n",
        "\n",
        "# Load global model weights\n",
        "server.model.load_weights(\"my_model.weights.h5\")\n",
        "\n",
        "# global model sends its weights to all devices\n",
        "server.give_global_model_weights_to_bitstring_devices(bitstring)\n",
        "\n",
        "test_loss, test_acc = server.evaluate(verbose=0)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "print(\"------------------------------------------------------------\")\n",
        "fit_bitstring_devices(bitstring, server)\n",
        "server.model.set_weights(server.aggregate_weights(bitstring))\n",
        "print(\"------------------------------------------------------------\")\n",
        "test_loss, test_acc = server.evaluate(verbose=0)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XliqF4L-Sd",
        "outputId": "613396eb-907f-4edd-8fc4-1446524053b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymoo in d:\\github repos\\fl\\venv\\lib\\site-packages (0.6.1.3)\n",
            "Requirement already satisfied: numpy>=1.15 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
            "Requirement already satisfied: cma==3.2.2 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
            "Requirement already satisfied: alive-progress in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
            "Requirement already satisfied: dill in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
            "Requirement already satisfied: Deprecated in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\github repos\\fl\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Requirement already satisfied: about-time==4.2.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWyAIYBDQ0a"
      },
      "source": [
        "## NSGA2 Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hiEDWLPjHqJt"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "NUM_ROUNDS = 3 # was 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_random_binary_list(size):\n",
        "    return [random.randint(0, 1) for _ in range(size)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM0EBc17HqJu",
        "outputId": "2f73767f-beaf-451d-eef0-46457ebd604e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 959us/step - accuracy: 0.6170 - loss: 1.8464\n",
            "(1.8564454317092896, 0.6134999990463257)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 827us/step - accuracy: 0.6170 - loss: 1.8464\n",
            "(1.8564454317092896, 0.6134999990463257)\n",
            "Bitstring:  [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1]\n",
            "14 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 827us/step - accuracy: 0.6170 - loss: 1.8464\n",
            "Global Model Accuracy: 0.6135\n",
            "------------------------------------------------------------\n",
            "1  1\n",
            "1  2\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 1.6816 \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 1.2002 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.9815 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.8139 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.6939 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.6023 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.5110 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4787 - loss: 1.6991 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5147 - loss: 1.2904 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5019 - loss: 1.2429 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 1.0839 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.9922 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6561 - loss: 0.9838 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.7806 \n",
            "4.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 1.4295 \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.9120 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 0.7157 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.7055 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.6258 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.5050 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.5048 \n",
            "5.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 1.5727 \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 1.0433 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.8146 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.6495 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.6103 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.5399 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.4751 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7104 - loss: 1.5351 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6421 - loss: 1.1453 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.9992 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.8728 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 0.7781 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.6032 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.5857 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7021 - loss: 1.5674 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 0.9236 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.7889 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.5845 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.4816 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.5050 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.4401 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 1.8777 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7092 - loss: 1.5598 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6670 - loss: 1.4389 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6394 - loss: 1.3636 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6571 - loss: 1.2172 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6696 - loss: 1.1512 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7191 - loss: 1.0650 \n",
            "18.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7743 - loss: 1.6666 \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 1.2699 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 1.0855 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7976 - loss: 0.9080 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.7714 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.7202 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.6173 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6417 - loss: 1.7627 \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7260 - loss: 1.3607\n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6559 - loss: 1.2811 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7560 - loss: 1.1404 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7383 - loss: 1.0502\n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7872 - loss: 0.9324\n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7677 - loss: 0.9086 \n",
            "23.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6855 - loss: 1.4794 \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7261 - loss: 1.0027 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.7591 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.5780 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.5311 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.4382 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.4021 \n",
            "26.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 1.5540 \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7486 - loss: 1.0215 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.8777 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.6759 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8420 - loss: 0.5910 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.5028 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.5361 \n",
            "27.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6229 - loss: 1.6602 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.9974 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8260 - loss: 0.8386 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.6930 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.6493 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.5720 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.5392 \n",
            "28.0\n",
            "2  3\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "18.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "26.0\n",
            "*******************\n",
            "27.0\n",
            "*******************\n",
            "28.0\n",
            "*******************\n",
            "29.0\n",
            "[0.12645939918667193, 0.0687393414666142, 0.08867899776990686, 0.09366391184573003, 0.04171585989767808, 0.05562114653023745, 0.0836940836940837, 0.02886002886002886, 0.06480388298570117, 0.02203856749311295, 0.10756919847828939, 0.12593467138921685, 0.08238226420044602, 0.009838646202282565]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "2  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 901us/step - accuracy: 0.6982 - loss: 1.1409\n",
            "Global Model Accuracy: 0.7080\n",
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 891us/step - accuracy: 0.6982 - loss: 1.1409\n",
            "(1.1635158061981201, 0.7080000042915344)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 806us/step - accuracy: 0.6982 - loss: 1.1409\n",
            "(1.1635158061981201, 0.7080000042915344)\n",
            "Bitstring:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "13 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 815us/step - accuracy: 0.6982 - loss: 1.1409\n",
            "Global Model Accuracy: 0.7080\n",
            "------------------------------------------------------------\n",
            "2  1\n",
            "2  2\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.9997 \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.6931 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.6260 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.5057 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.4826 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.3958 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.4017 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6461 - loss: 1.2259 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.7366 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7871 - loss: 0.7698 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 0.6406 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.6010 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.5792 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.5459 \n",
            "3.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.6643 \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.4934 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.4570 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.3721 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.3698 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.3574 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3516 \n",
            "5.0\n",
            "Epoch 1/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.8917 \n",
            "Epoch 2/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.5311 \n",
            "Epoch 3/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.4073 \n",
            "Epoch 4/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8945 - loss: 0.3895 \n",
            "Epoch 5/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.2929 \n",
            "Epoch 6/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.2883 \n",
            "Epoch 7/7\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.2849 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.9211 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.5294 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.4082 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.3850 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.4190 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.3176 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.3280 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.9541 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.7083 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.5895 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.5191 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.4268 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.4318 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.3801 \n",
            "14.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7789 - loss: 0.9436 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 0.7207 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.6666 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8488 - loss: 0.6096 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8706 - loss: 0.5377 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8982 - loss: 0.5165 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8971 - loss: 0.4822 \n",
            "17.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.9337 \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.6283 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9190 - loss: 0.5767 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9002 - loss: 0.4418 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.4036 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9301 - loss: 0.3822 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.3875 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 0.9218 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.6414 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.5783 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.5064 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.4873 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.4303 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8984 - loss: 0.4118 \n",
            "21.0\n",
            "3  3\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "3.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "14.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "29.0\n",
            "[0.18264494126563094, 0.05759757483895415, 0.12807881773399016, 0.12353164077302008, 0.12087912087912088, 0.10306934444865479, 0.020335985853227233, 0.04660856384994316, 0.09359605911330049, 0.07805987116331944, 0.021220159151193636, 0.014904635594290767, 0.0094732853353543]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "3  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 818us/step - accuracy: 0.8391 - loss: 0.7455\n",
            "Global Model Accuracy: 0.8385\n",
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 826us/step - accuracy: 0.8391 - loss: 0.7455\n",
            "(0.7786343097686768, 0.8385000228881836)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 842us/step - accuracy: 0.8391 - loss: 0.7455\n",
            "(0.7786343097686768, 0.8385000228881836)\n",
            "Bitstring:  [0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n",
            "19 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 821us/step - accuracy: 0.8391 - loss: 0.7455\n",
            "Global Model Accuracy: 0.8385\n",
            "------------------------------------------------------------\n",
            "3  1\n",
            "3  2\n",
            "Epoch 1/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 0.6593 \n",
            "Epoch 2/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.6029 \n",
            "Epoch 3/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.4789 \n",
            "Epoch 4/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.3908 \n",
            "Epoch 5/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.3662 \n",
            "Epoch 6/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.3618 \n",
            "Epoch 7/7\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.3223\n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7700 - loss: 0.8860 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.7097 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.6725 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8986 - loss: 0.5837 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8418 - loss: 0.6238 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8583 - loss: 0.5825 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.4721 \n",
            "2.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.7351 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8675 - loss: 0.6458 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8793 - loss: 0.6375 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8946 - loss: 0.5760 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9025 - loss: 0.5416 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9036 - loss: 0.5137 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9494 - loss: 0.4694 \n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.5829 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.3969 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.3730 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9329 - loss: 0.3260 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9462 - loss: 0.2917 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9534 - loss: 0.2890 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.2822 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.6065 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.3419 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.3162 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.2684 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9319 - loss: 0.2999 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.2221 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.2496 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.7514 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8799 - loss: 0.5402 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8639 - loss: 0.4954 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.4822 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8929 - loss: 0.4238 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8881 - loss: 0.4416 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.4053 \n",
            "13.0\n",
            "Epoch 1/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 0.8650 \n",
            "Epoch 2/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5920 - loss: 1.0312 \n",
            "Epoch 3/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.5960 \n",
            "Epoch 4/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8478 - loss: 0.5281 \n",
            "Epoch 5/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.5404 \n",
            "Epoch 6/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.4579 \n",
            "Epoch 7/7\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7245 - loss: 0.7774 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.5983 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.5288 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9173 - loss: 0.3602 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.3683 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.3051 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9219 - loss: 0.3186 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.2773 \n",
            "21.0\n",
            "4  3\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "2.0\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "28.0\n",
            "*******************\n",
            "29.0\n",
            "[0.15761935905820798, 0.0618051013734467, 0.04283845650752126, 0.0828973185088293, 0.03507194244604317, 0.03433616742969261, 0.025997383911052975, 0.06932635709614127, 0.10431654676258993, 0.047416612164813604, 0.0735775016350556, 0.0301667756703728, 0.06057880967952911, 0.06736429038587312, 0.025833878351863963, 0.013734466971877045, 0.009646827992151734, 0.0513407455853499, 0.006131458469587966]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "4  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 809us/step - accuracy: 0.8798 - loss: 0.6861\n",
            "Global Model Accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "\n",
        "all_runs_fronts = []  # Stores results across runs\n",
        "all_runs_solutions = []\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "    # Step 3: Run Optimization\n",
        "    print(\"GLOBAL MODEL BEFORE OPTIMIZATION\")\n",
        "    print(server.evaluate())\n",
        "\n",
        "    print(\"GLOBAL MODEL AFTER OPTIMIZATION\")\n",
        "    print(server.evaluate())\n",
        "\n",
        "    bitstring = generate_random_binary_list(len(devices))\n",
        "    print(\"Bitstring: \", bitstring)\n",
        "    print(bitstring.count(1), \"devices selected randomly\")\n",
        "\n",
        "    a = server.model.get_weights()\n",
        "    test_loss, test_acc = server.evaluate()\n",
        "    print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    print(server.current_learning_iteration, \" 1\")\n",
        "    server.give_global_model_weights_to_bitstring_devices(bitstring)\n",
        "    print(server.current_learning_iteration, \" 2\")\n",
        "    fit_bitstring_devices(bitstring, server=server, epochs=7)\n",
        "    print(server.current_learning_iteration, \" 3\")\n",
        "    server.model.set_weights(server.aggregate_weights(bitstring))\n",
        "    print(server.current_learning_iteration, \" 4\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    test_loss, test_acc = server.evaluate()\n",
        "    print(f\"Global Model Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Choose a generation and run\n",
        "gen_idx = 0\n",
        "run_idx = 0\n",
        "\n",
        "for run_idx in range(len(all_runs_fronts)):\n",
        "    for gen_idx in range(len(all_runs_fronts[run_idx])):\n",
        "        \n",
        "        front = all_runs_fronts[run_idx][gen_idx]\n",
        "\n",
        "        fig = go.Figure(data=[go.Scatter3d(\n",
        "            x=front[:, 0],\n",
        "            y=front[:, 1],\n",
        "            z=front[:, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=5,\n",
        "                color=front[:, 2],  # Color by third objective\n",
        "                colorscale='Viridis',\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Pareto Front - Run {run_idx}, Gen {gen_idx}\",\n",
        "            scene=dict(\n",
        "                xaxis=dict(title=\"Objective 1\", range=[0, 1]),\n",
        "                yaxis=dict(title=\"Objective 2\", range=[0, 1]),\n",
        "                zaxis=dict(title=\"Objective 3\", range=[0, 1])\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 829us/step - accuracy: 0.8798 - loss: 0.6861\n",
            "(0.724544107913971, 0.875)\n"
          ]
        }
      ],
      "source": [
        "print(server.evaluate())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
