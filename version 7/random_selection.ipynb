{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cM8_9f7DQ0P"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cE4i_ysDeI4",
        "outputId": "206a1e08-bf7c-4146-db82-e4b11c33880a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymoo in d:\\github repos\\fl\\venv\\lib\\site-packages (0.6.1.3)\n",
            "Requirement already satisfied: numpy>=1.15 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
            "Requirement already satisfied: cma==3.2.2 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
            "Requirement already satisfied: alive-progress in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
            "Requirement already satisfied: dill in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
            "Requirement already satisfied: Deprecated in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\github repos\\fl\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Requirement already satisfied: about-time==4.2.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7ZDVPjAODQ0R"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import random\n",
        "from tensorflow.keras.models import clone_model\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6jG5c5fDQ0S"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eRjGPts0DQ0T"
      },
      "outputs": [],
      "source": [
        "# CLASSES\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, devices_list):\n",
        "        self.model = Server.create_model()\n",
        "        self.current_learning_iteration = 0\n",
        "        self.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES = []\n",
        "        self.x_test_global = []\n",
        "        self.y_test_global = []\n",
        "        self.devices = devices_list\n",
        "\n",
        "    # def evaluate(self, verbose = 1):\n",
        "    #     test_loss, test_acc = self.model.evaluate(self.x_test_global, self.y_test_global, verbose)\n",
        "    #     return test_loss, test_acc\n",
        "\n",
        "    def evaluate(self, x_test=None, y_test=None, verbose = 1):\n",
        "        if x_test is None and y_test is None:\n",
        "            test_loss, test_acc = self.model.evaluate(self.x_test_global, self.y_test_global, verbose)\n",
        "            return test_loss, test_acc\n",
        "        test_loss, test_acc = self.model.evaluate(x_test, y_test, verbose=verbose)\n",
        "        return test_loss, test_acc\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def set_aggregated_weight(self):\n",
        "        self.model.set_weight(Server.aggregate_weights())\n",
        "\n",
        "    def give_global_model_weights_to_bitstring_devices(self, bitstring):\n",
        "        for device in self.devices:\n",
        "            if int(bitstring[int(device.id)]) == 1:\n",
        "                device.model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def create_model():\n",
        "        model = keras.Sequential([\n",
        "            layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "                        # new\n",
        "                        loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def aggregate_weights(self, bitstring):\n",
        "        \"\"\"Computes the weighted average of model weights from all devices and updates the global model.\"\"\"\n",
        "        def sum_all_nested_lists(list_of_lists):\n",
        "            def recursive_sum(lists):\n",
        "                if isinstance(lists[0], list):\n",
        "                    return [recursive_sum([lst[i] for lst in lists]) for i in range(len(lists[0]))]\n",
        "                else:\n",
        "                    return sum(lists)\n",
        "\n",
        "            return recursive_sum(list_of_lists)\n",
        "\n",
        "        def multiply_nested_list(lst, factor):\n",
        "            result = []\n",
        "            for item in lst:\n",
        "                if isinstance(item, list):\n",
        "                    # Recursively handle sublists\n",
        "                    result.append(multiply_nested_list(item, factor))\n",
        "                else:\n",
        "                    # Multiply number\n",
        "                    result.append(item * factor)\n",
        "            return result\n",
        "\n",
        "        selected_devices = []\n",
        "        for device in self.devices:\n",
        "            if int(bitstring[int(device.id)]) == 1:\n",
        "                selected_devices.append(device)\n",
        "\n",
        "        num_devices = len(selected_devices)\n",
        "        if num_devices == 0:\n",
        "            print(\"No devices available for aggregation.\")\n",
        "            return\n",
        "\n",
        "        device_participation_ratio = []\n",
        "        data_lengths = []\n",
        "\n",
        "        for device in selected_devices:\n",
        "            print(\"*******************\")\n",
        "            print(device.id)\n",
        "            device_participation_ratio.append(device.last_round_participated / self.current_learning_iteration)\n",
        "            # print(\"this device's participation ratio:\")\n",
        "            # print(device.last_round_participated / self.current_learning_iteration)\n",
        "            data_lengths.append(len(device.data[0]))\n",
        "            # print(\"this device's data to all ratio:\")\n",
        "            # print(len(device.data[0])/60000.0)\n",
        "\n",
        "        sum_data = 0\n",
        "        for data_len in data_lengths:\n",
        "            sum_data += data_len\n",
        "\n",
        "        data_fractions = []\n",
        "        for device in selected_devices:\n",
        "            data_fractions.append(len(device.data[0])/float(sum_data))\n",
        "\n",
        "\n",
        "\n",
        "        # new\n",
        "        combined_weights = [fraction * ratio for fraction, ratio in zip(data_fractions, device_participation_ratio)]\n",
        "        total_weight = sum(combined_weights)\n",
        "        normalized_weights = [w / total_weight for w in combined_weights]\n",
        "        print(normalized_weights)\n",
        "\n",
        "\n",
        "        aggregated_weights_devices = []\n",
        "        for d in range(len(selected_devices)):\n",
        "            # aggregated_weights_devices.append(multiply_nested_list(selected_devices[d].model.get_weights(), data_fractions[d]*device_participation_ratio[d]))\n",
        "            aggregated_weights_devices.append(multiply_nested_list(self.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES[int(selected_devices[d].id)], normalized_weights[d]))\n",
        "\n",
        "        aggregated_weights = sum_all_nested_lists(aggregated_weights_devices)\n",
        "        # TODO: Weighted multiplication for each node in each layer of the neural network of the received devices and then summing\n",
        "        #       the related parts together so that we get a full weighted average of all these devices' models\n",
        "\n",
        "        print(\"Aggregated weights:\")\n",
        "        for layer_idx, layer_weights in enumerate(aggregated_weights):\n",
        "            print(f\"Layer {layer_idx}: {layer_weights.shape}\")\n",
        "            \n",
        "        \n",
        "        return aggregated_weights\n",
        "\n",
        "\n",
        "class Device:\n",
        "    def __init__(self, id, ram, storage, cpu, bandwidth, battery, charging):\n",
        "        self.id = id\n",
        "        self.ram = ram\n",
        "        self.storage = storage\n",
        "        self.cpu = cpu\n",
        "        self.bandwidth = bandwidth\n",
        "        self.battery = battery\n",
        "        self.charging = charging\n",
        "        self.model = Server.create_model()\n",
        "        self.last_round_participated = 0\n",
        "        self.data = None  # Placeholder for dataset partition\n",
        "        self.test_data = None\n",
        "        self.number_of_times_fitted = 0\n",
        "        \n",
        "    def lose_battery(self):\n",
        "        if float(self.battery) > 0.3:\n",
        "            self.battery -= 0.3\n",
        "        else:\n",
        "            self.battery = 0\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3jpr0sQDQ0U"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YSAsTf5GDQ0V"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "\n",
        "def fit_bitstring_devices(bitstring, server: Server, epochs=7):\n",
        "    '''\n",
        "    server: for using its \"current_learning_iteration\" variable\n",
        "    '''\n",
        "\n",
        "    server.current_learning_iteration += 1\n",
        "    for device in server.devices:\n",
        "        if bitstring[int(device.id)] == 1:\n",
        "            # new\n",
        "            device.lose_battery()\n",
        "            \n",
        "            device.model.fit(device.data[0], device.data[1], epochs=epochs, verbose=1)\n",
        "            print(device.id)\n",
        "            device.last_round_participated = server.current_learning_iteration\n",
        "            server.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES[int(device.id)] = device.model.get_weights()\n",
        "            device.number_of_times_fitted += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def niid_labeldir_split(x_data, y_data, num_clients, beta):\n",
        "    num_classes = 10\n",
        "    y_indices = np.array([np.argmax(label) for label in y_data])  # From one-hot to class index\n",
        "\n",
        "    # Prepare client partitions\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for k in range(num_classes):\n",
        "        idx_k = np.where(y_indices == k)[0]\n",
        "        np.random.shuffle(idx_k)\n",
        "\n",
        "        # Dirichlet distribution for class k\n",
        "        proportions = np.random.dirichlet(np.repeat(beta, num_clients))\n",
        "\n",
        "        # Scale proportions to match the number of available samples\n",
        "        proportions = np.array([int(p * len(idx_k)) for p in proportions])\n",
        "        # Fix total due to rounding\n",
        "        while sum(proportions) < len(idx_k):\n",
        "            proportions[np.argmin(proportions)] += 1\n",
        "        while sum(proportions) > len(idx_k):\n",
        "            proportions[np.argmax(proportions)] -= 1\n",
        "\n",
        "        start = 0\n",
        "        for i in range(num_clients):\n",
        "            size = proportions[i]\n",
        "            client_indices[i].extend(idx_k[start:start + size])\n",
        "            start += size\n",
        "\n",
        "    return client_indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_M11zZDQ0W"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8SKaZfTDQ0W"
      },
      "source": [
        "### Load Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp1Ba7wUDQ0W",
        "outputId": "5d017ddf-25eb-46b0-f6e3-5ec61e2bf722"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Github Repos\\FL\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset from CSV\n",
        "csv_file = 'devices.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Convert CSV rows into device objects\n",
        "devices = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    device = Device(\n",
        "        row['id'], row['ram'], row['storage'], row['cpu'], row['bandwidth'], row['battery'],\n",
        "        row.get('charging', 0)\n",
        "    )\n",
        "    devices.append(device)\n",
        "\n",
        "\n",
        "# LIMIT TO 30 DEVICES\n",
        "devices = devices[:30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dQSqJi6DQ0Y"
      },
      "source": [
        "### Object Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OvVt3SZzDQ0Z"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "server = Server(devices_list=devices)\n",
        "server.LAST_WEIGHTS_SENT_FOR_ALL_DEVICES = [None for _ in range(len(devices))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hodxc61dDQ0Z"
      },
      "source": [
        "### Split Data Among Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ySmgcIuDQ0Z",
        "outputId": "5b32be3b-f118-4bda-c12d-0bfdf1e74f2c"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Convert labels to categorical (one-hot encoded)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Normalize data and reshape for CNN\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)  # Add channel dimension\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1)  # Add channel dimension\n",
        "\n",
        "# Shuffle data\n",
        "# indices = np.arange(len(x_train))\n",
        "# np.random.shuffle(indices)\n",
        "# x_train, y_train = x_train[indices], y_train[indices]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# new\n",
        "# Lower the amount of data for devices\n",
        "x_train = x_train[:int(len(x_train)/8)]\n",
        "y_train = y_train[:int(len(y_train)/8)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Correct test split\n",
        "split_index = int(0.8 * len(x_test))\n",
        "x_test_devices, y_test_devices = x_test[:split_index], y_test[:split_index]\n",
        "server.x_test_global, server.y_test_global = x_test[split_index:], y_test[split_index:]\n",
        "\n",
        "# Training data (for devices)\n",
        "x_train_devices, y_train_devices = x_train, y_train\n",
        "\n",
        "# Split training data among devices\n",
        "beta = 0.5  # lower = more skewed\n",
        "num_devices = len(devices)\n",
        "split_indices = niid_labeldir_split(x_train_devices, y_train_devices, num_devices, beta)\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    idxs = split_indices[i]\n",
        "    device.data = (x_train_devices[idxs], y_train_devices[idxs])\n",
        "\n",
        "# Split test data (device-level)\n",
        "split_size = len(x_test_devices) // num_devices\n",
        "\n",
        "for i, device in enumerate(devices):\n",
        "    start = i * split_size\n",
        "    end = (i + 1) * split_size if i < num_devices - 1 else len(x_test_devices)\n",
        "    device.test_data = (x_test_devices[start:end], y_test_devices[start:end])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXlJ81PvDQ0Z"
      },
      "source": [
        "### Load Other Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtD_ODCDQ0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFERpbpDQ0Z"
      },
      "source": [
        "## First Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtoM8SQmHqJs",
        "outputId": "0b9ad23e-e90e-47f5-f416-bd856dfd56a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0748 - loss: 2.3148\n",
            "Global Model Accuracy: 0.0755\n",
            "------------------------------------------------------------\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0888 - loss: 2.2931  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4498 - loss: 2.1917 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4581 - loss: 2.0806 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4414 - loss: 1.9876 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4394 - loss: 1.8971 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4081 - loss: 1.8110 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4008 - loss: 1.7596 \n",
            "0.0\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1071 - loss: 2.2626  \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5133 - loss: 2.1667 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4993 - loss: 2.0392 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5504 - loss: 1.9923 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5340 - loss: 1.8424 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4844 - loss: 1.7597 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5524 - loss: 1.6822 \n",
            "1.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1098 - loss: 2.3063  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2079 - loss: 2.1941 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4101 - loss: 2.0818 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4997 - loss: 1.9540 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 1.7892 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5717 - loss: 1.6532 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 1.5279 \n",
            "2.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2114 - loss: 2.2538  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4091 - loss: 2.0932 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5186 - loss: 1.8827 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 1.7603 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6254 - loss: 1.5303 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 1.4224 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 1.2809 \n",
            "3.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0394 - loss: 2.3319  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3154 - loss: 2.2071 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3355 - loss: 2.0791 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3513 - loss: 1.9704 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4155 - loss: 1.7783 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4704 - loss: 1.6624 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6101 - loss: 1.4997 \n",
            "4.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1179 - loss: 2.3098  \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2710 - loss: 2.2410 \n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4119 - loss: 2.1953 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4215 - loss: 2.1449 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4413 - loss: 2.0633 \n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3827 - loss: 2.0284 \n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4061 - loss: 1.9334 \n",
            "5.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3357 - loss: 2.2163  \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 1.9738 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6143 - loss: 1.7188 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6718 - loss: 1.4503 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6662 - loss: 1.3015 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6730 - loss: 1.3024 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 1.1431 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2108 - loss: 2.2530      \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5279 - loss: 1.8773 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 1.6191 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4971 - loss: 1.5119 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5601 - loss: 1.2861 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5307 - loss: 1.3413 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5794 - loss: 1.1790 \n",
            "7.0\n",
            "Epoch 1/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0526 - loss: 2.2870 \n",
            "Epoch 2/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1688 - loss: 2.2684\n",
            "Epoch 3/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4421 - loss: 2.2320\n",
            "Epoch 4/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5261 - loss: 2.2044\n",
            "Epoch 5/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4947 - loss: 2.1846\n",
            "Epoch 6/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4947 - loss: 2.1496\n",
            "Epoch 7/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4841 - loss: 2.1108\n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2624 - loss: 2.2205  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6812 - loss: 1.5332 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6805 - loss: 1.1195 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6384 - loss: 1.0977 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.9305 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.8898 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.7925 \n",
            "9.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0606 - loss: 2.3392  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3102 - loss: 2.2476 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4946 - loss: 2.1591 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5674 - loss: 2.0583 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5570 - loss: 1.9721 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5715 - loss: 1.8911 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5589 - loss: 1.8222 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1945 - loss: 2.2465  \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2744 - loss: 2.0552 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4266 - loss: 1.8104 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5885 - loss: 1.5816 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 1.3183 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6746 - loss: 1.2116 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.9819 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2316 - loss: 2.2613  \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3141 - loss: 2.1337 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3196 - loss: 1.9961 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3389 - loss: 1.8613 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3999 - loss: 1.7431 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5141 - loss: 1.5753 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 1.4839 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2784 - loss: 2.1975  \n",
            "Epoch 2/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2836 - loss: 1.8405 \n",
            "Epoch 3/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4732 - loss: 1.5385 \n",
            "Epoch 4/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 1.2184 \n",
            "Epoch 5/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.9768 \n",
            "Epoch 6/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.8612 \n",
            "Epoch 7/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.6985 \n",
            "13.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0948 - loss: 2.3039  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4896 - loss: 2.1578 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 1.9932 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5687 - loss: 1.7977 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5567 - loss: 1.6171 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5843 - loss: 1.4205 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 1.2578 \n",
            "14.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1752 - loss: 2.2678  \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3015 - loss: 2.1479 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3627 - loss: 2.0018 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5033 - loss: 1.8374 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5075 - loss: 1.7633 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4980 - loss: 1.6757 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5203 - loss: 1.5744 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2979 - loss: 2.2202  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6453 - loss: 1.7650 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6400 - loss: 1.4022 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6298 - loss: 1.2934 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6472 - loss: 1.2216 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 1.1049 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 1.1019 \n",
            "16.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0937 - loss: 2.3187  \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3228 - loss: 2.2270 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4015 - loss: 2.1652 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3440 - loss: 2.0816 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3234 - loss: 1.9923 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3291 - loss: 1.9030 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3200 - loss: 1.8103 \n",
            "17.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1415 - loss: 2.2606  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4890 - loss: 2.1690 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5721 - loss: 2.0551 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6294 - loss: 1.9208 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6071 - loss: 1.7906 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 1.6931 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5855 - loss: 1.5692 \n",
            "18.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2714 - loss: 2.2215  \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4740 - loss: 1.8218 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4605 - loss: 1.5145 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: 1.2879 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6827 - loss: 1.2355 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6882 - loss: 1.0866 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6993 - loss: 1.0766 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1814 - loss: 2.2793  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5038 - loss: 1.9730 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4638 - loss: 1.6767 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4934 - loss: 1.3885 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5378 - loss: 1.2184 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 1.0930 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7798 - loss: 0.9426 \n",
            "20.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2130 - loss: 2.2547  \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4294 - loss: 2.0136 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 1.6677 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 1.3997 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 1.1678 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 1.0379 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.8752 \n",
            "21.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2829 - loss: 2.2187  \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5762 - loss: 1.9414 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 1.6028 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 1.4104 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 1.0945 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 1.0147 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.9852 \n",
            "22.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3400 - loss: 2.1850  \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5523 - loss: 1.7197 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5429 - loss: 1.3327 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5525 - loss: 1.1575 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6171 - loss: 1.0549 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7129 - loss: 0.8685 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.8448 \n",
            "23.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1051 - loss: 2.2832  \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5736 - loss: 2.1491 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6159 - loss: 1.9965 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5591 - loss: 1.8346 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5853 - loss: 1.6772 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 1.4276 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6735 - loss: 1.3782 \n",
            "24.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1811 - loss: 2.2836      \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5472 - loss: 2.0706 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5303 - loss: 1.8197 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 1.5784 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5648 - loss: 1.4096 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6636 - loss: 1.1605 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 1.0494 \n",
            "25.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0620 - loss: 2.3098      \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3708 - loss: 2.2129 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4682 - loss: 2.1321 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5066 - loss: 2.0241 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4905 - loss: 1.9210 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4934 - loss: 1.8193 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5161 - loss: 1.7088 \n",
            "26.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0451 - loss: 2.3108      \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2154 - loss: 2.2206 \n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3964 - loss: 2.1470 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4611 - loss: 2.0273 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3830 - loss: 1.9811 \n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4377 - loss: 1.8362 \n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4377 - loss: 1.7396 \n",
            "27.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0812 - loss: 2.3211      \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5388 - loss: 2.1448 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5340 - loss: 1.9628 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5158 - loss: 1.7765 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5501 - loss: 1.5707 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 1.4313 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5748 - loss: 1.2879 \n",
            "28.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0624 - loss: 2.3023      \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4937 - loss: 2.0626 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4693 - loss: 1.8023 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5751 - loss: 1.5547 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 1.3337 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 1.1375 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.9265 \n",
            "29.0\n",
            "*******************\n",
            "0.0\n",
            "*******************\n",
            "1.0\n",
            "*******************\n",
            "2.0\n",
            "*******************\n",
            "3.0\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "9.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "14.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "17.0\n",
            "*******************\n",
            "18.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "20.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "26.0\n",
            "*******************\n",
            "27.0\n",
            "*******************\n",
            "28.0\n",
            "*******************\n",
            "29.0\n",
            "[0.0152, 0.013066666666666667, 0.024266666666666666, 0.04226666666666667, 0.022133333333333335, 0.0116, 0.028933333333333332, 0.0472, 0.0084, 0.040933333333333335, 0.025333333333333333, 0.061066666666666665, 0.028933333333333332, 0.0768, 0.036533333333333334, 0.028266666666666666, 0.04253333333333333, 0.021066666666666668, 0.024666666666666667, 0.0484, 0.036533333333333334, 0.054266666666666664, 0.0368, 0.041466666666666666, 0.0232, 0.05053333333333333, 0.02493333333333333, 0.012, 0.0208, 0.051866666666666665]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "------------------------------------------------------------\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5726 - loss: 1.8601\n",
            "Global Model Accuracy: 0.5475\n"
          ]
        }
      ],
      "source": [
        "# First Iteration\n",
        "bitstring = [1 for _ in range(len(devices))]\n",
        "print(bitstring)\n",
        "\n",
        "# global model sends its weights to all devices\n",
        "server.give_global_model_weights_to_bitstring_devices(bitstring)\n",
        "\n",
        "test_loss, test_acc = server.evaluate(verbose=0)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "print(\"------------------------------------------------------------\")\n",
        "fit_bitstring_devices(bitstring, server)\n",
        "server.model.set_weights(server.aggregate_weights(bitstring))\n",
        "print(\"------------------------------------------------------------\")\n",
        "test_loss, test_acc = server.evaluate(verbose=0)\n",
        "print(f\"Global Model Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XliqF4L-Sd",
        "outputId": "613396eb-907f-4edd-8fc4-1446524053b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymoo in d:\\github repos\\fl\\venv\\lib\\site-packages (0.6.1.3)\n",
            "Requirement already satisfied: numpy>=1.15 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.7.0)\n",
            "Requirement already satisfied: cma==3.2.2 in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.2)\n",
            "Requirement already satisfied: alive-progress in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (3.2.0)\n",
            "Requirement already satisfied: dill in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (0.3.9)\n",
            "Requirement already satisfied: Deprecated in d:\\github repos\\fl\\venv\\lib\\site-packages (from pymoo) (1.2.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\github repos\\fl\\venv\\lib\\site-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\github repos\\fl\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Requirement already satisfied: about-time==4.2.1 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in d:\\github repos\\fl\\venv\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in d:\\github repos\\fl\\venv\\lib\\site-packages (from Deprecated->pymoo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NWyAIYBDQ0a"
      },
      "source": [
        "## NSGA2 Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hiEDWLPjHqJt"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "NUM_ROUNDS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_random_binary_list(size):\n",
        "    return [random.randint(0, 1) for _ in range(size)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM0EBc17HqJu",
        "outputId": "2f73767f-beaf-451d-eef0-46457ebd604e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 794us/step - accuracy: 0.5716 - loss: 1.8607\n",
            "(1.8750598430633545, 0.5475000143051147)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 783us/step - accuracy: 0.5716 - loss: 1.8607\n",
            "(1.8750598430633545, 0.5475000143051147)\n",
            "Bitstring:  [0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "15 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 797us/step - accuracy: 0.5716 - loss: 1.8607\n",
            "Global Model Accuracy: 0.5475\n",
            "------------------------------------------------------------\n",
            "1  1\n",
            "1  2\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 1.8473 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5970 - loss: 1.4142 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7063 - loss: 1.1856 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7747 - loss: 1.0841 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 1.0023 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7627 - loss: 0.9114 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.8447 \n",
            "4.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6651 - loss: 1.5372 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 1.1812 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7114 - loss: 1.0358 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.8532 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8013 - loss: 0.8972 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.7791 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.7720 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 1.6755 \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5440 - loss: 1.2813 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 1.1418 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6777 - loss: 0.9711 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6963 - loss: 0.9060 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.7797 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.7334 \n",
            "7.0\n",
            "Epoch 1/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5265 - loss: 1.9104\n",
            "Epoch 2/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6318 - loss: 1.7474\n",
            "Epoch 3/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6104 - loss: 1.6302\n",
            "Epoch 4/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5789 - loss: 1.5515\n",
            "Epoch 5/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5372 - loss: 1.5517\n",
            "Epoch 6/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5891 - loss: 1.4337\n",
            "Epoch 7/7\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5683 - loss: 1.4320\n",
            "8.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5640 - loss: 1.8565 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6035 - loss: 1.5509 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6116 - loss: 1.4199 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6148 - loss: 1.3285 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6273 - loss: 1.2204 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6762 - loss: 1.2075 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 1.1530 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6495 - loss: 1.6426 \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 1.1856 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.9494 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.7583 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.7083 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.6371 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8479 - loss: 0.5157 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6241 - loss: 1.7266 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 1.3682 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 1.1427 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 1.0226 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.8939 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.7634 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.7430 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7012 - loss: 1.5134 \n",
            "Epoch 2/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 1.0570 \n",
            "Epoch 3/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7986 - loss: 0.7941 \n",
            "Epoch 4/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.6683 \n",
            "Epoch 5/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.5709 \n",
            "Epoch 6/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.4788 \n",
            "Epoch 7/7\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.4270 \n",
            "13.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4950 - loss: 1.8162 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5849 - loss: 1.4866 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6107 - loss: 1.3546 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5962 - loss: 1.2762 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6696 - loss: 1.1325 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7505 - loss: 1.0501 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 1.0080 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 1.6458 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 1.3082 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 1.1269 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 1.0190 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 0.9281 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.7704 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.6868 \n",
            "18.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5531 - loss: 1.6575 \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6539 - loss: 1.1420 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.9273 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.8682 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7745 - loss: 0.8609 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.6761 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.6439 \n",
            "19.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 1.5461 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 1.0005 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.8509 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.7475 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.6617 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.6162 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.5685 \n",
            "22.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7110 - loss: 1.6281 \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 1.1742 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7473 - loss: 0.9953 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.8369 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.7504 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.6305 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.6433 \n",
            "25.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6529 - loss: 1.7664 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5807 - loss: 1.1801 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7133 - loss: 0.9600 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.8805 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.7923 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.7315 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.7396 \n",
            "28.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 1.6463 \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 1.1611 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.9425 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.7996 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.6467 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.5796 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.5322 \n",
            "29.0\n",
            "2  3\n",
            "*******************\n",
            "4.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "8.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "13.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "18.0\n",
            "*******************\n",
            "19.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "25.0\n",
            "*******************\n",
            "28.0\n",
            "*******************\n",
            "29.0\n",
            "[0.039514401333015946, 0.05165436800761723, 0.08426565103546775, 0.014996429421566294, 0.04522732682694597, 0.10902166150916448, 0.05165436800761723, 0.1371102118543204, 0.050464175196381814, 0.04403713401571054, 0.0864079980956915, 0.0656986431801952, 0.09021661509164484, 0.03713401571054511, 0.09259700071411568]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "2  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 779us/step - accuracy: 0.8104 - loss: 1.0463\n",
            "Global Model Accuracy: 0.7960\n",
            "GLOBAL MODEL BEFORE OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782us/step - accuracy: 0.8104 - loss: 1.0463\n",
            "(1.0773392915725708, 0.7960000038146973)\n",
            "GLOBAL MODEL AFTER OPTIMIZATION\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 769us/step - accuracy: 0.8104 - loss: 1.0463\n",
            "(1.0773392915725708, 0.7960000038146973)\n",
            "Bitstring:  [1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "17 devices selected randomly\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782us/step - accuracy: 0.8104 - loss: 1.0463\n",
            "Global Model Accuracy: 0.7960\n",
            "------------------------------------------------------------\n",
            "2  1\n",
            "2  2\n",
            "Epoch 1/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 1.0800 \n",
            "Epoch 2/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8020 - loss: 0.8094 \n",
            "Epoch 3/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.7564 \n",
            "Epoch 4/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 0.7245 \n",
            "Epoch 5/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8299 - loss: 0.6883 \n",
            "Epoch 6/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.6171 \n",
            "Epoch 7/7\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8829 - loss: 0.5787 \n",
            "0.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.8471 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.6149 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.5776 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 0.4834 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.4252 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.4089 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.3619 \n",
            "3.0\n",
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7134 - loss: 1.2190 \n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8143 - loss: 0.8838 \n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7718 - loss: 0.8255 \n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8492 - loss: 0.7684 \n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8396 - loss: 0.7096 \n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8373 - loss: 0.6779 \n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.6588 \n",
            "5.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.8440 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.6871 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.5394 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.6055 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.4790 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.4524 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9127 - loss: 0.3977 \n",
            "6.0\n",
            "Epoch 1/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7497 - loss: 1.0173 \n",
            "Epoch 2/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.7842 \n",
            "Epoch 3/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.6879 \n",
            "Epoch 4/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.5558 \n",
            "Epoch 5/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.5915 \n",
            "Epoch 6/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.5164 \n",
            "Epoch 7/7\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.4907 \n",
            "7.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 1.0735 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.8610 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.8414 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.8314 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.7501 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.6532 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 0.6590 \n",
            "10.0\n",
            "Epoch 1/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.8711 \n",
            "Epoch 2/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.6287 \n",
            "Epoch 3/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.5397 \n",
            "Epoch 4/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.4851 \n",
            "Epoch 5/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.4667 \n",
            "Epoch 6/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.3986 \n",
            "Epoch 7/7\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.3311 \n",
            "11.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.9846 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.6788 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.5879 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.4816 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.4839 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.4657 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.3995 \n",
            "12.0\n",
            "Epoch 1/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6593 - loss: 1.2715 \n",
            "Epoch 2/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7795 - loss: 0.9327 \n",
            "Epoch 3/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.8365 \n",
            "Epoch 4/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8416 - loss: 0.7207 \n",
            "Epoch 5/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.7240 \n",
            "Epoch 6/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.6819 \n",
            "Epoch 7/7\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.6144 \n",
            "15.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.9451 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8492 - loss: 0.5600 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.5243 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.3552 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.3848 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.3764 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9581 - loss: 0.3282 \n",
            "16.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8876 - loss: 0.8208 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.6455 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.5272 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.4884 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9166 - loss: 0.4631 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9130 - loss: 0.4895 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9331 - loss: 0.4109 \n",
            "18.0\n",
            "Epoch 1/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 1.0297 \n",
            "Epoch 2/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.6568 \n",
            "Epoch 3/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.6072 \n",
            "Epoch 4/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.4954 \n",
            "Epoch 5/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.4582 \n",
            "Epoch 6/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.3855 \n",
            "Epoch 7/7\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.4558 \n",
            "21.0\n",
            "Epoch 1/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.8158 \n",
            "Epoch 2/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.4878 \n",
            "Epoch 3/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.4413 \n",
            "Epoch 4/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.4279 \n",
            "Epoch 5/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.3981 \n",
            "Epoch 6/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.3320 \n",
            "Epoch 7/7\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.3439 \n",
            "22.0\n",
            "Epoch 1/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8217 - loss: 0.8596 \n",
            "Epoch 2/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.5392 \n",
            "Epoch 3/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.4053 \n",
            "Epoch 4/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.4621 \n",
            "Epoch 5/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8941 - loss: 0.3866 \n",
            "Epoch 6/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.3300 \n",
            "Epoch 7/7\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.3192 \n",
            "23.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9113 - loss: 0.8808 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9039 - loss: 0.6106 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.5336 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.4913 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.4709 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.3995 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.3669 \n",
            "24.0\n",
            "Epoch 1/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 1.0015 \n",
            "Epoch 2/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.7870 \n",
            "Epoch 3/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.7116 \n",
            "Epoch 4/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.5962 \n",
            "Epoch 5/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.5873 \n",
            "Epoch 6/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.5120 \n",
            "Epoch 7/7\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.4790 \n",
            "26.0\n",
            "Epoch 1/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8710 - loss: 0.8741 \n",
            "Epoch 2/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8736 - loss: 0.5231 \n",
            "Epoch 3/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8587 - loss: 0.5188 \n",
            "Epoch 4/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.4444 \n",
            "Epoch 5/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.3987 \n",
            "Epoch 6/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.3845 \n",
            "Epoch 7/7\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8855 - loss: 0.4252 \n",
            "28.0\n",
            "3  3\n",
            "*******************\n",
            "0.0\n",
            "*******************\n",
            "3.0\n",
            "*******************\n",
            "5.0\n",
            "*******************\n",
            "6.0\n",
            "*******************\n",
            "7.0\n",
            "*******************\n",
            "10.0\n",
            "*******************\n",
            "11.0\n",
            "*******************\n",
            "12.0\n",
            "*******************\n",
            "15.0\n",
            "*******************\n",
            "16.0\n",
            "*******************\n",
            "18.0\n",
            "*******************\n",
            "21.0\n",
            "*******************\n",
            "22.0\n",
            "*******************\n",
            "23.0\n",
            "*******************\n",
            "24.0\n",
            "*******************\n",
            "26.0\n",
            "*******************\n",
            "28.0\n",
            "[0.0272662042573547, 0.07581918201387228, 0.020808419038507536, 0.051901458981105, 0.08466873953599617, 0.04544367376225783, 0.10954317149007414, 0.051901458981105, 0.05070557282946663, 0.07629753647452762, 0.04424778761061947, 0.09734513274336283, 0.06601291557043769, 0.07438411863190625, 0.04161683807701507, 0.044726142071274816, 0.03731164793111696]\n",
            "Aggregated weights:\n",
            "Layer 0: (3, 3, 1, 32)\n",
            "Layer 1: (32,)\n",
            "Layer 2: (5408, 128)\n",
            "Layer 3: (128,)\n",
            "Layer 4: (128, 10)\n",
            "Layer 5: (10,)\n",
            "3  4\n",
            "------------------------------------------------------------\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step - accuracy: 0.7974 - loss: 0.7052\n",
            "Global Model Accuracy: 0.7940\n"
          ]
        }
      ],
      "source": [
        "\n",
        "all_runs_fronts = []  # Stores results across runs\n",
        "all_runs_solutions = []\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "    # Step 3: Run Optimization\n",
        "    print(\"GLOBAL MODEL BEFORE OPTIMIZATION\")\n",
        "    print(server.evaluate())\n",
        "\n",
        "    print(\"GLOBAL MODEL AFTER OPTIMIZATION\")\n",
        "    print(server.evaluate())\n",
        "\n",
        "    bitstring = generate_random_binary_list(len(devices))\n",
        "    print(\"Bitstring: \", bitstring)\n",
        "    print(bitstring.count(1), \"devices selected randomly\")\n",
        "\n",
        "    a = server.model.get_weights()\n",
        "    test_loss, test_acc = server.evaluate()\n",
        "    print(f\"Global Model Accuracy: {test_acc:.4f}\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    print(server.current_learning_iteration, \" 1\")\n",
        "    server.give_global_model_weights_to_bitstring_devices(bitstring)\n",
        "    print(server.current_learning_iteration, \" 2\")\n",
        "    fit_bitstring_devices(bitstring, server=server, epochs=7)\n",
        "    print(server.current_learning_iteration, \" 3\")\n",
        "    server.model.set_weights(server.aggregate_weights(bitstring))\n",
        "    print(server.current_learning_iteration, \" 4\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "    test_loss, test_acc = server.evaluate()\n",
        "    print(f\"Global Model Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Choose a generation and run\n",
        "gen_idx = 0\n",
        "run_idx = 0\n",
        "\n",
        "for run_idx in range(len(all_runs_fronts)):\n",
        "    for gen_idx in range(len(all_runs_fronts[run_idx])):\n",
        "        \n",
        "        front = all_runs_fronts[run_idx][gen_idx]\n",
        "\n",
        "        fig = go.Figure(data=[go.Scatter3d(\n",
        "            x=front[:, 0],\n",
        "            y=front[:, 1],\n",
        "            z=front[:, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=5,\n",
        "                color=front[:, 2],  # Color by third objective\n",
        "                colorscale='Viridis',\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"Pareto Front - Run {run_idx}, Gen {gen_idx}\",\n",
        "            scene=dict(\n",
        "                xaxis=dict(title=\"Objective 1\", range=[0, 1]),\n",
        "                yaxis=dict(title=\"Objective 2\", range=[0, 1]),\n",
        "                zaxis=dict(title=\"Objective 3\", range=[0, 1])\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 820us/step - accuracy: 0.7974 - loss: 0.7052\n",
            "(0.7341400384902954, 0.7940000295639038)\n"
          ]
        }
      ],
      "source": [
        "print(server.evaluate())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
